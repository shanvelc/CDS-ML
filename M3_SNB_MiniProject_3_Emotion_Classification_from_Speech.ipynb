{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanvelc/CDS-ML/blob/main/M3_SNB_MiniProject_3_Emotion_Classification_from_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "associate-sunset",
      "metadata": {
        "id": "associate-sunset"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Mini-Project: Speech Emotion Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n-kxaHhwXEp9",
      "metadata": {
        "id": "n-kxaHhwXEp9"
      },
      "source": [
        "**DISCLAIMER:** THIS NOTEBOOK IS PROVIDED ONLY AS A REFERENCE SOLUTION NOTEBOOK FOR THE MINI-PROJECT. THERE MAY BE OTHER POSSIBLE APPROACHES/METHODS TO ACHIEVE THE SAME RESULTS."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "handled-tooth",
      "metadata": {
        "id": "handled-tooth"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accessory-watts",
      "metadata": {
        "id": "accessory-watts"
      },
      "source": [
        "Build a model to recognize emotion from speech using Ensemble learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "twenty-indonesia",
      "metadata": {
        "id": "twenty-indonesia"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ZGAsPzQAU-X",
      "metadata": {
        "id": "1ZGAsPzQAU-X"
      },
      "source": [
        "At the end of the mini-project, you will be able to :\n",
        "\n",
        "* extract the features from audio data\n",
        "* implement ML classification algorithms individually and as Ensembles, to classify emotions\n",
        "* record the voice sample and test it with trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lesbian-bottom",
      "metadata": {
        "id": "lesbian-bottom"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fixed-trainer",
      "metadata": {
        "id": "fixed-trainer"
      },
      "source": [
        "**TESS Dataset**\n",
        "\n",
        "The first dataset chosen for this mini-project is the [TESS](https://dataverse.scholarsportal.info/dataset.xhtml?persistentId=doi:10.5683/SP2/E8H2MF) (Toronto emotional speech set) dataset. It contains 2880 files.  A set of 200 target words were spoken in the carrier phrase \"Say the word _____' by two actresses and the sets were recorded in seven different emotions (anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral). Both actresses spoke English as their first language, were university educated, and had musical training. Audiometric testing indicated that both actresses had thresholds within the normal range."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Roo5A2aLVI07",
      "metadata": {
        "id": "Roo5A2aLVI07"
      },
      "source": [
        "**Ravdess Dataset**\n",
        "\n",
        "The second dataset chosen for this mini-project is [Ravdess](https://zenodo.org/record/1188976#.YLczy4XivIU) (The Ryerson Audio-Visual Database of Emotional Speech and Song). This dataset contains 1440 files: 60 trials per actor x 24 actors = 1440. The RAVDESS contains 24 professional actors (12 female, 12 male), vocalizing two lexically-matched statements in a neutral North American accent. Speech emotions includes calm, happy, sad, angry, fearful, surprise, and disgust expressions. Each expression is produced at two levels of emotional intensity (normal, strong), with an additional neutral expression.\n",
        "\n",
        "**File naming convention**\n",
        "\n",
        "Each of the 1440 files has a unique filename. The filename consists of a 7-part numerical identifier (e.g., 03-01-06-01-02-01-12.wav). These identifiers define the stimulus characteristics:\n",
        "\n",
        "**Filename identifiers**\n",
        "\n",
        "* Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "* Vocal channel (01 = speech, 02 = song).\n",
        "* Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "* Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "* Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "* Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "* Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "\n",
        "Filename example: `03-01-06-01-02-01-12.wav`\n",
        "\n",
        "    - Audio-only - 03\n",
        "    - Speech - 01\n",
        "    - Fearful - 06\n",
        "    - Normal intensity - 01\n",
        "    - Statement \"dogs\" - 02\n",
        "    - 1st Repetition - 01\n",
        "    - 12th Actor - 12 Female, as the actor ID number is even."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GIR6a6TvVnRY",
      "metadata": {
        "id": "GIR6a6TvVnRY"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mediterranean-february",
      "metadata": {
        "id": "mediterranean-february"
      },
      "source": [
        "**Speech Emotion Recognition (SER)** is the task of recognizing the emotion from  speech, irrespective of the semantics. Humans can efficiently perform this task as a natural part of speech communication, however, the ability to conduct it automatically using programmable devices is a field of active research.\n",
        "\n",
        "Studies of automatic emotion recognition systems aim to create efficient, real-time methods of detecting the emotions of mobile phone users, call center operators and customers, car drivers, pilots, and many other human-machine communication users. Adding emotions to machines forms an important aspect of making machines appear and act in a human-like manner\n",
        "\n",
        "Lets gain familiarity with some of the audio based features that are commonly used for SER.\n",
        "\n",
        "**Mel scale** — The mel scale (derived from the word *melody*) is a perceptual scale of pitches judged by listeners to be equal in distance from one another. The reference point between this scale and normal frequency measurement is defined by assigning a perceptual pitch of 1000 mels to a 1000 Hz tone, 40 dB above the listener's threshold. Above about 500 Hz, increasingly large intervals are judged by listeners to produce equal pitch increments. Refer [here](https://towardsdatascience.com/learning-from-audio-the-mel-scale-mel-spectrograms-and-mel-frequency-cepstral-coefficients-f5752b6324a8) for more detailed information.\n",
        "\n",
        "**Pitch** — how high or low a sound is. It depends on frequency, higher pitch is high frequency\n",
        "\n",
        "**Frequency** — speed of vibration of sound, measures wave cycles per second\n",
        "\n",
        "**Chroma** — Representation for audio where spectrum is projected onto 12 bins representing the 12 distinct semitones (or chroma). Computed by summing the log frequency magnitude spectrum across octaves.\n",
        "\n",
        "**Fourier Transforms** — used to convert from time domain to frequency domain. Time domain shows how signal changes over time. Frequency domain shows how much of the signal lies within each given frequency band over a range of frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q5a6Dz9wCxOc",
      "metadata": {
        "id": "Q5a6Dz9wCxOc"
      },
      "source": [
        "**Librosa**\n",
        "\n",
        "[Librosa](https://librosa.org/doc/latest/index.html) is a Python package, built for speech and audio analytics. It provides modular functions that simplify working with audio data and help in achieving a wide range of applications such as identification of the personal characteristics of different individuals' voice samples, detecting emotions from audio samples etc.\n",
        "\n",
        "For further details on the Librosa package, refer [here](https://conference.scipy.org/proceedings/scipy2015/pdfs/brian_mcfee.pdf).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lEGMJDoiGJL6",
      "metadata": {
        "id": "lEGMJDoiGJL6"
      },
      "source": [
        "### **Kaggle Competition**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z6AaUizRGPiG",
      "metadata": {
        "id": "z6AaUizRGPiG"
      },
      "source": [
        "Please refer to the link for viewing the\n",
        "[Kaggle Competition Document](https://drive.google.com/file/d/1bSX5aV8jD39Lk8FpcJpCabY5TKgtHb49/view?usp=sharing) and join the Kaggle Competition using the hyperlink given in this document under '*Kaggle* Competition site'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "operating-latter",
      "metadata": {
        "id": "operating-latter"
      },
      "source": [
        "## Grading = 10 Points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "talented-upset",
      "metadata": {
        "cellView": "form",
        "id": "talented-upset"
      },
      "outputs": [],
      "source": [
        "#@title Download the dataset\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/Ravdess_Tess.zip\n",
        "!unzip -qq Ravdess_Tess.zip\n",
        "# Install packages\n",
        "!pip -qq install librosa soundfile\n",
        "!pip -qq install wavio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "appreciated-pattern",
      "metadata": {
        "id": "appreciated-pattern"
      },
      "source": [
        "### Import Neccesary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loose-marsh",
      "metadata": {
        "id": "loose-marsh"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import IPython.display as ipd\n",
        "from matplotlib import pyplot as plt\n",
        "from datetime import datetime\n",
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import VotingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2vxa85gvorY5",
      "metadata": {
        "id": "2vxa85gvorY5"
      },
      "source": [
        "### Work-Flow\n",
        "\n",
        "* Load the TESS audio data and extract features and labels\n",
        "\n",
        "* Load the Ravdess audio data and extract features\n",
        "\n",
        "* Combine both the audio dataset features\n",
        "\n",
        "* Train and test the model with TESS + Ravdess Data\n",
        "\n",
        "* Record the team audio samples and add them to TESS + Ravdess data\n",
        "\n",
        "* Train and test the model with TESS + Ravdess + Team Recorded (combined) data\n",
        "\n",
        "* Test each of the models with live audio sample recording."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_UtviWIXAtb4",
      "metadata": {
        "id": "_UtviWIXAtb4"
      },
      "source": [
        "### Load the Tess data and Ravdess data audio files (1 point)\n",
        "\n",
        "Hint: `glob.glob`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518e945a",
      "metadata": {
        "id": "518e945a"
      },
      "outputs": [],
      "source": [
        "wav_files = glob.glob(\"Tess/*/*.wav\")\n",
        "len(wav_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sound-chest",
      "metadata": {
        "id": "sound-chest"
      },
      "source": [
        "#### Play the sample audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "personalized-wildlife",
      "metadata": {
        "id": "personalized-wildlife"
      },
      "outputs": [],
      "source": [
        "ipd.Audio('Tess/YAF_fear/YAF_cool_fear.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exposed-county",
      "metadata": {
        "id": "exposed-county"
      },
      "source": [
        "### Data Exploration and Visualization (1 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hungry-cleaner",
      "metadata": {
        "id": "hungry-cleaner"
      },
      "source": [
        "#### Visualize the distribution of all the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "political-jerusalem",
      "metadata": {
        "id": "political-jerusalem"
      },
      "outputs": [],
      "source": [
        "emotions_ = []\n",
        "for file in wav_files:\n",
        "    emotions_.append(file.split(\"_\")[-1][:-4])\n",
        "set(emotions_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "orange-taiwan",
      "metadata": {
        "id": "orange-taiwan"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "freq_emotions = Counter(emotions_)\n",
        "plt.bar(freq_emotions.keys(),freq_emotions.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "established-airfare",
      "metadata": {
        "id": "established-airfare"
      },
      "source": [
        "#### Visualize sample audio signal using librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "outstanding-caribbean",
      "metadata": {
        "id": "outstanding-caribbean"
      },
      "outputs": [],
      "source": [
        "sample_audio_path = 'Tess/YAF_fear/YAF_cool_fear.wav'\n",
        "\n",
        "# librosa is used for analyzing and extracting features of an audio signal\n",
        "data, sampling_rate = librosa.load(sample_audio_path)\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# librosa.display.waveshow is used to plot waveform of amplitude vs time\n",
        "librosa.display.waveshow(data, sr=sampling_rate)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "medical-confidence",
      "metadata": {
        "id": "medical-confidence"
      },
      "source": [
        "### Feature extraction (2 points)\n",
        "\n",
        "Read one WAV file at a time using `Librosa`. An audio time series in the form of a 1-dimensional array for mono or 2-dimensional array for stereo, along with time sampling rate (which defines the length of the array), where the elements within each of the arrays represent the amplitude of the sound waves is returned by `librosa.load()` function. Refer to the supplementary notebook ('Audio feature extraction')\n",
        "\n",
        "To know more about Librosa, explore the [link](https://librosa.org/doc/latest/feature.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "superb-scotland",
      "metadata": {
        "id": "superb-scotland"
      },
      "outputs": [],
      "source": [
        "def extract_feature(file_name):\n",
        "    \"\"\"Function Extracts Features from WAV file\"\"\"\n",
        "    X, sample_rate = librosa.load(file_name)\n",
        "    stft=np.abs(librosa.stft(X))\n",
        "    result=np.array([])\n",
        "    mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "    result=np.hstack((result, mfccs))\n",
        "    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "    result=np.hstack((result, chroma))\n",
        "    mel=np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
        "    result=np.hstack((result, mel))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "piano-accent",
      "metadata": {
        "id": "piano-accent"
      },
      "outputs": [],
      "source": [
        "sample_feature = extract_feature(wav_files[0]) #,mfcc=True, chroma=True, mel=True)\n",
        "sample_feature.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3bd640",
      "metadata": {
        "id": "7d3bd640"
      },
      "source": [
        "#### Create a dictionary or a function to encode the emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c8d44d",
      "metadata": {
        "id": "c0c8d44d"
      },
      "outputs": [],
      "source": [
        "emotions = {'angry':5, 'disgust':7, 'fear':6, 'happy':3, 'neutral':1, 'surprised':8, 'sad':4}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coupled-villa",
      "metadata": {
        "id": "coupled-villa"
      },
      "source": [
        "#### TESS data feature extraction\n",
        "\n",
        "**Note:** Features are already saved in DataFrame and given in csv file, Ignore the below commented code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "quarterly-adrian",
      "metadata": {
        "id": "quarterly-adrian"
      },
      "outputs": [],
      "source": [
        "# Load the data and extract features for each sound file\n",
        "# tess_x, tess_y = [], []\n",
        "# for file_name in wav_files:\n",
        "#     emotion = emotions[file_name.split(\"_\")[-1][:-4]]\n",
        "#     feature = extract_feature(file_name)\n",
        "#     tess_x.append(feature)\n",
        "#     tess_y.append(emotion)\n",
        "\n",
        "# len(tess_x), len(tess_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3XJMGdYXEQmE",
      "metadata": {
        "id": "3XJMGdYXEQmE"
      },
      "outputs": [],
      "source": [
        "# set(tess_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qKzclsG-FnW6",
      "metadata": {
        "id": "qKzclsG-FnW6"
      },
      "source": [
        "#### Ravdess data feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WS8Hk_e9GN69",
      "metadata": {
        "id": "WS8Hk_e9GN69"
      },
      "outputs": [],
      "source": [
        "rav_wav_files = glob.glob(\"ravdess/*/*.wav\")\n",
        "len(rav_wav_files), rav_wav_files[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C20Km6geFq77",
      "metadata": {
        "id": "C20Km6geFq77"
      },
      "outputs": [],
      "source": [
        "# rav_x, rav_y = [], []\n",
        "# for file_name in rav_wav_files:\n",
        "#     emotion = emotions[file_name.split(\"_\")[-1][:-4]]\n",
        "#     feature = extract_feature(file_name)\n",
        "#     rav_x.append(feature)\n",
        "#     rav_y.append(emotion)\n",
        "# len(rav_x), len(rav_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "itI8bT3jHcrk",
      "metadata": {
        "id": "itI8bT3jHcrk"
      },
      "outputs": [],
      "source": [
        "# set(rav_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iDwNOgKEIH3w",
      "metadata": {
        "id": "iDwNOgKEIH3w"
      },
      "outputs": [],
      "source": [
        "# features = tess_x + rav_x\n",
        "# labels = tess_y + rav_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kLkbEo2zY2bO",
      "metadata": {
        "id": "kLkbEo2zY2bO"
      },
      "outputs": [],
      "source": [
        "# Download extracted features csv\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/tess_ravdess_features.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eoULlEdZYGiP",
      "metadata": {
        "id": "eoULlEdZYGiP"
      },
      "outputs": [],
      "source": [
        "extracted = pd.read_csv(\"tess_ravdess_features.csv\")\n",
        "features = extracted.iloc[:,:-1]\n",
        "labels = extracted.iloc[:,-1]\n",
        "features.shape, labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb62f16",
      "metadata": {
        "id": "2bb62f16"
      },
      "source": [
        "#### Save the features\n",
        "\n",
        "It is best advised to save the features in dataframe and maintain so that feature extraction step is not required to be performed every time.\n",
        "\n",
        "* Make a DataFrame with features and labels\n",
        "\n",
        "* Write dataframe into `.CSV` file and save it offline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec91c16",
      "metadata": {
        "id": "9ec91c16"
      },
      "outputs": [],
      "source": [
        "# saved_data = pd.DataFrame(features)\n",
        "# saved_data['label'] = labels\n",
        "# saved_data.to_csv(\"tess_ravdess_features.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aggressive-cause",
      "metadata": {
        "id": "aggressive-cause"
      },
      "source": [
        "#### Split the data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nearby-angle",
      "metadata": {
        "id": "nearby-angle"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(np.array(features), np.array(labels), test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, len(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ordered-weapon",
      "metadata": {
        "id": "ordered-weapon"
      },
      "source": [
        "### Train the model with TESS + Ravdess data (2 points)\n",
        "\n",
        "* Apply different ML algorithms (eg. DecisionTree, RandomForest, etc.) and find the model with best performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbobpjK7379X",
      "metadata": {
        "id": "cbobpjK7379X"
      },
      "source": [
        "#### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8y7efGFBIfqj",
      "metadata": {
        "id": "8y7efGFBIfqj"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "lr.score(X_test, y_test), lr.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D9p5BFgWfqsa",
      "metadata": {
        "id": "D9p5BFgWfqsa"
      },
      "outputs": [],
      "source": [
        "# Feature Importance using LogisticRegression\n",
        "lr_coefficients = lr.coef_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8kU-TWFWjVdq",
      "metadata": {
        "id": "8kU-TWFWjVdq"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame for feature importance\n",
        "logistic_feature_importance = pd.DataFrame({\n",
        "    'Feature': features.columns,\n",
        "    'Importance': lr_coefficients\n",
        "})\n",
        "\n",
        "# Sort the features by importance\n",
        "logistic_feature_importance = logistic_feature_importance.sort_values(by='Importance', ascending=False)\n",
        "print(logistic_feature_importance)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=logistic_feature_importance)\n",
        "plt.title('Feature Importance in Logistic Regression')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bmAHyPId4oB3",
      "metadata": {
        "id": "bmAHyPId4oB3"
      },
      "source": [
        "#### DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extraordinary-fault",
      "metadata": {
        "id": "extraordinary-fault"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "from sklearn import tree\n",
        "\n",
        "dt_model = tree.DecisionTreeClassifier(random_state=42)\n",
        "dt_model = dt_model.fit(X_train, y_train)\n",
        "dt_model.score(X_test, y_test), dt_model.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xnma_HlFogud",
      "metadata": {
        "id": "Xnma_HlFogud"
      },
      "outputs": [],
      "source": [
        "# Feature Importances using DecisionTreeClassifier\n",
        "\n",
        "# Getting the feature importances\n",
        "dt_feature_importances = dt_model.feature_importances_\n",
        "\n",
        "# Creating a DataFrame for feature importance\n",
        "dt_feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features.columns,\n",
        "    'Importance': dt_feature_importances\n",
        "})\n",
        "\n",
        "# Sort the features by importance\n",
        "dt_feature_importance_df = dt_feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "print(dt_feature_importance_df)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=dt_feature_importance_df)\n",
        "plt.title('Feature Importance in Decision Tree')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UyD8gqUE4uV9",
      "metadata": {
        "id": "UyD8gqUE4uV9"
      },
      "source": [
        "#### RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "civic-palestine",
      "metadata": {
        "id": "civic-palestine"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_model.score(X_test, y_test), rf_model.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SlP5P0_Ypsmg",
      "metadata": {
        "id": "SlP5P0_Ypsmg"
      },
      "outputs": [],
      "source": [
        "# Feature Importances using RandomForestClassifier\n",
        "# Get the feature importances\n",
        "rf_feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for feature importance\n",
        "rf_feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features.columns,\n",
        "    'Importance': rf_feature_importances\n",
        "})\n",
        "\n",
        "# Sort the features by importance\n",
        "rf_feature_importance_df = rf_feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "print(rf_feature_importance_df)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=rf_feature_importance_df)\n",
        "plt.title('Feature Importance in Random Forest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CFX0KCvW42kZ",
      "metadata": {
        "id": "CFX0KCvW42kZ"
      },
      "source": [
        "#### LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gzCe1APDUpg0",
      "metadata": {
        "id": "gzCe1APDUpg0"
      },
      "outputs": [],
      "source": [
        "#Linear SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "Lsvm = LinearSVC(random_state=0, tol=1e-5)\n",
        "Lsvm.fit(X_train, y_train)\n",
        "Lsvm.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zbQVv8DYqdw_",
      "metadata": {
        "id": "zbQVv8DYqdw_"
      },
      "outputs": [],
      "source": [
        "# Feature Importances using LinearSVC\n",
        "# Get the feature importances (coefficients)\n",
        "linearSVC_coefficients = Lsvm.coef_[0]\n",
        "\n",
        "# Create a DataFrame for feature importance\n",
        "linearSVC_feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features.columns,\n",
        "    'Importance': linearSVC_coefficients\n",
        "})\n",
        "\n",
        "# Sort the features by importance\n",
        "linearSVC_feature_importance_df = linearSVC_feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "print(linearSVC_feature_importance_df)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=linearSVC_feature_importance_df)\n",
        "plt.title('Feature Importance in Linear SVC')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5MVybNGC49CO",
      "metadata": {
        "id": "5MVybNGC49CO"
      },
      "source": [
        "#### SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EtlfZmtWSD_X",
      "metadata": {
        "id": "EtlfZmtWSD_X"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n",
        "\n",
        "sgd.fit(X_train, y_train)\n",
        "sgd.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bm_mKPgZrMqw",
      "metadata": {
        "id": "Bm_mKPgZrMqw"
      },
      "outputs": [],
      "source": [
        "# Feature Importances using SGDClassifier\n",
        "# Get the feature importances (coefficients)\n",
        "sgd_coefficients = sgd.coef_[0]\n",
        "\n",
        "# Create a DataFrame for feature importance\n",
        "sgd_feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features.columns,\n",
        "    'Importance': sgd_coefficients\n",
        "})\n",
        "\n",
        "# Sort the features by importance\n",
        "sgd_feature_importance_df = sgd_feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "print(sgd_feature_importance_df)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=sgd_feature_importance_df)\n",
        "plt.title('Feature Importance in SGD Classifier')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "248GMRPy5DsV",
      "metadata": {
        "id": "248GMRPy5DsV"
      },
      "source": [
        "#### XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qAteWIO6x8_v",
      "metadata": {
        "id": "qAteWIO6x8_v"
      },
      "outputs": [],
      "source": [
        "# XGBoost Classifier\n",
        "# Encode labels to be zero-based\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(features), np.array(encoded_labels), test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the XGBClassifier model\n",
        "num_classes = len(np.unique(encoded_labels))\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',  # Multi-class classification objective\n",
        "    num_class=num_classes,       # Number of unique classes\n",
        "    colsample_bytree=0.3,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    alpha=10,\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Reverse the encoding of predictions\n",
        "y_pred_original = label_encoder.inverse_transform(y_pred)\n",
        "y_test_original = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_original, y_pred_original)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pvkZU6yp52G-",
      "metadata": {
        "id": "pvkZU6yp52G-"
      },
      "outputs": [],
      "source": [
        "# Feature Importances using XGBClassifier\n",
        "# Display feature importances\n",
        "xgb_feature_importances = xgb_model.feature_importances_\n",
        "feature_names = features.columns\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "xgb_feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': xgb_feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(xgb_feature_importance_df)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=xgb_feature_importance_df)\n",
        "plt.title('Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "returning-bones",
      "metadata": {
        "id": "returning-bones"
      },
      "source": [
        "#### Apply the voting classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fuzzy-respondent",
      "metadata": {
        "id": "fuzzy-respondent"
      },
      "outputs": [],
      "source": [
        "# Voting classifer\n",
        "lr = LogisticRegression(random_state=42)\n",
        "dt = tree.DecisionTreeClassifier(random_state=42)\n",
        "rf_model_v = RandomForestClassifier(random_state=42)\n",
        "Lsvm = LinearSVC(random_state=0, tol=1e-5)\n",
        "sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',  # Multi-class classification objective\n",
        "    num_class=num_classes,       # Number of unique classes\n",
        "    colsample_bytree=0.3,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    alpha=10,\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "voting = VotingClassifier(estimators=[('lr',lr), ('dt', dt), ('rf', rf_model_v), ('sgd', sgd),('Lsvm',Lsvm), ('xgb', xgb_model)], voting='hard')\n",
        "voting = voting.fit(X_train, y_train)\n",
        "voting.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vb9SktJUsIdz",
      "metadata": {
        "id": "Vb9SktJUsIdz"
      },
      "outputs": [],
      "source": [
        "# Feature Importances using VotingClassifier\n",
        "# Combine feature importances into a DataFrame for visualization\n",
        "features_list = features.columns\n",
        "\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features_list,\n",
        "    'Decision Tree Importance': dt_feature_importances,\n",
        "    'Random Forest Importance': rf_feature_importances,\n",
        "    'Logistic Regression Importance': lr_coefficients,\n",
        "    'Linear SVC Importance': linearSVC_coefficients,\n",
        "    'SGD Importance': sgd_coefficients,\n",
        "    'XGB Importance': xgb_feature_importances\n",
        "})\n",
        "feature_importance_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H6zqpYer5jSH",
      "metadata": {
        "id": "H6zqpYer5jSH"
      },
      "source": [
        "- min and max feature importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MWjG7TafwNN-",
      "metadata": {
        "id": "MWjG7TafwNN-"
      },
      "outputs": [],
      "source": [
        "# Calculate min and max feature importances\n",
        "min_importances = {\n",
        "    'Logistic Regression': lr_coefficients.min(),\n",
        "    'Decision Tree': dt_feature_importances.min(),\n",
        "    'Random Forest': rf_feature_importances.min(),\n",
        "    'Linear SVC': linearSVC_coefficients.min(),\n",
        "    'SGD': sgd_coefficients.min(),\n",
        "    'XGB': xgb_feature_importances.min()\n",
        "}\n",
        "\n",
        "max_importances = {\n",
        "    'Logistic Regression': lr_coefficients.max(),\n",
        "    'Decision Tree': dt_feature_importances.max(),\n",
        "    'Random Forest': rf_feature_importances.max(),\n",
        "    'Linear SVC': linearSVC_coefficients.max(),\n",
        "    'SGD': sgd_coefficients.max(),\n",
        "    'XGB': xgb_feature_importances.max()\n",
        "}\n",
        "\n",
        "# Combine min and max values into a DataFrame\n",
        "feature_importance_min_max_df = pd.DataFrame({\n",
        "    'Classifier': min_importances.keys(),\n",
        "    'Min Importance': min_importances.values(),\n",
        "    'Max Importance': max_importances.values()\n",
        "})\n",
        "feature_importance_min_max_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forced-spider",
      "metadata": {
        "id": "forced-spider"
      },
      "source": [
        "#### Testing with a sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "first-negotiation",
      "metadata": {
        "id": "first-negotiation"
      },
      "outputs": [],
      "source": [
        "# audio sample\n",
        "test_sample = 'Tess/YAF_fear/YAF_cool_fear.wav'\n",
        "ipd.Audio(test_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surprising-liability",
      "metadata": {
        "id": "surprising-liability"
      },
      "outputs": [],
      "source": [
        "# prediction\n",
        "pred = rf_model.predict(extract_feature(test_sample).reshape(1,-1))\n",
        "list(emotions.keys())[list(emotions.values()).index(int(pred[0]))]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6p1MHeY9oYqB",
      "metadata": {
        "id": "6p1MHeY9oYqB"
      },
      "source": [
        "### Train the model with TESS + Ravdess + Team recorded data (2 points)\n",
        "\n",
        "* Record the audio samples, extract features and combine with TESS data features\n",
        "  - Record and gather all the team data with proper naming convention in separate folder\n",
        "\n",
        "    **Hint:** Follow the supplementary notebook\n",
        "\n",
        "  - Each team member must record 2 samples for each emotion (Use similar sentences as given in TESS data)\n",
        "\n",
        "* Train the different ML algorithms and find the model with best performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M4In88rvtVmb",
      "metadata": {
        "id": "M4In88rvtVmb"
      },
      "source": [
        "#### Load the team data\n",
        "\n",
        "**Note:** Upload your team data by running the below cell and proceed with next cells\n",
        "\n",
        "<font color=\"red\">If the team data is not uploaded in the following cell, subsequent cells may result in errors.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DbrkFH8c2F22",
      "metadata": {
        "id": "DbrkFH8c2F22"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GqBFZhYw2Ifm",
      "metadata": {
        "id": "GqBFZhYw2Ifm"
      },
      "outputs": [],
      "source": [
        "!unzip -qq # Path here to unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MxdN3240GuOq",
      "metadata": {
        "id": "MxdN3240GuOq"
      },
      "source": [
        "**Change the path below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WY2bEPUs2Lw_",
      "metadata": {
        "id": "WY2bEPUs2Lw_"
      },
      "outputs": [],
      "source": [
        "TeamData = glob.glob(\"/content/path_to_folder/*.wav\")\n",
        "len(TeamData)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U9XfHW21BJOs",
      "metadata": {
        "id": "U9XfHW21BJOs"
      },
      "source": [
        "#### Extracting features of team data and combine with TESS + Ravdess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yIw9Febi2PRN",
      "metadata": {
        "id": "yIw9Febi2PRN"
      },
      "outputs": [],
      "source": [
        "# extracting team recorded data features\n",
        "team_features = []\n",
        "team_label = []\n",
        "for i in TeamData:\n",
        "  team_features.append(extract_feature(i))\n",
        "  emt = (i.split(\"_\")[-1][:-4]).strip()\n",
        "  team_label.append(emotions[emt])\n",
        "\n",
        "len(team_features),len(team_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v5Zcl-XK2TtL",
      "metadata": {
        "id": "v5Zcl-XK2TtL"
      },
      "outputs": [],
      "source": [
        "# combining team data with Tess + ravdess data\n",
        "all_x = list(features.values) + team_features\n",
        "all_y = list(labels) + team_label\n",
        "len(all_x), len(all_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RlsYGh5w2WkI",
      "metadata": {
        "id": "RlsYGh5w2WkI"
      },
      "outputs": [],
      "source": [
        "set(all_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w-ulIdIdtkDB",
      "metadata": {
        "id": "w-ulIdIdtkDB"
      },
      "source": [
        "#### Train the different ML algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z2p7TaI12ZzT",
      "metadata": {
        "id": "Z2p7TaI12ZzT"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(np.array(all_x), np.array(all_y), test_size=0.2, random_state=42)\n",
        "xtrain.shape, xtest.shape, len(ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UpGtF2E32cLA",
      "metadata": {
        "id": "UpGtF2E32cLA"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "dt_model_team = tree.DecisionTreeClassifier(random_state=42)\n",
        "dt_model_team = dt_model_team.fit(xtrain, ytrain)\n",
        "dt_model_team.score(xtest, ytest), dt_model_team.score(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QCtx9Hrq2fg8",
      "metadata": {
        "id": "QCtx9Hrq2fg8"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "rf_model_team = RandomForestClassifier(random_state=42)\n",
        "rf_model_team.fit(xtrain, ytrain)\n",
        "rf_model_team.score(xtest, ytest), rf_model_team.score(xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uYSOGUu32iPL",
      "metadata": {
        "id": "uYSOGUu32iPL"
      },
      "outputs": [],
      "source": [
        "#Linear SVC\n",
        "Lsvm = LinearSVC(random_state=0, tol=1e-5)\n",
        "Lsvm.fit(xtrain, ytrain)\n",
        "Lsvm.score(xtest, ytest)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iMl0sRhXtXzL",
      "metadata": {
        "id": "iMl0sRhXtXzL"
      },
      "source": [
        "### Test the best working model with live audio recording"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HzXXLCyH2l5e",
      "metadata": {
        "id": "HzXXLCyH2l5e"
      },
      "outputs": [],
      "source": [
        "MODEL = rf_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M2hwAj8q2sU1",
      "metadata": {
        "cellView": "form",
        "id": "M2hwAj8q2sU1"
      },
      "outputs": [],
      "source": [
        "#@title Speak the utterance and test\n",
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "if not os.path.exists('ModelTesting/'):\n",
        "    os.mkdir(\"ModelTesting/\")\n",
        "def record(sec=3):\n",
        "    print(\"Start speaking!\")\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    display(Javascript(RECORD))\n",
        "    s = output.eval_js('record(%d)' % (sec*1000))\n",
        "    b = b64decode(s.split(',')[1])\n",
        "    with open('ModelTesting/audio_'+current_time+'.wav','wb') as f:\n",
        "        f.write(b)\n",
        "    return 'ModelTesting/audio_'+current_time+'.wav'\n",
        "test_i = record()\n",
        "pred = MODEL.predict(extract_feature(test_i).reshape(1,-1))\n",
        "idx_emotion = list(emotions.values()).index(pred[0])\n",
        "print(list(emotions.keys())[idx_emotion])\n",
        "ipd.Audio(test_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K7n58VaeWKGu",
      "metadata": {
        "id": "K7n58VaeWKGu"
      },
      "source": [
        "### Report Analysis\n",
        "\n",
        "- Report the accuracy for 10 live samples using the model trained on TESS+Ravdess+Team data\n",
        "- Discuss with the team mentor regarding deep learnt audio features (which will be introduced in Module 5 for another audio classification task). Read a related article [here](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805181).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2C13NXh77NgW",
      "metadata": {
        "id": "2C13NXh77NgW"
      },
      "source": [
        "### Kaggle Testset predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LjTdIdbq-rN8",
      "metadata": {
        "id": "LjTdIdbq-rN8",
        "outputId": "db3bd14d-5494-4cc9-cf0c-f146c25bfb59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2ee98662-0f39-446b-9e10-f2c4130c02c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2ee98662-0f39-446b-9e10-f2c4130c02c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4vwgkYVM-thx",
      "metadata": {
        "id": "4vwgkYVM-thx"
      },
      "outputs": [],
      "source": [
        "!unzip -qq /content/Kaggle_Testset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BdzOvaBc-v2Z",
      "metadata": {
        "id": "BdzOvaBc-v2Z"
      },
      "outputs": [],
      "source": [
        "test_set = glob.glob(\"/content/Kaggle_Testset/*.wav\")\n",
        "test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0HCmvXJK-y9j",
      "metadata": {
        "id": "0HCmvXJK-y9j"
      },
      "outputs": [],
      "source": [
        "order = []\n",
        "testset_features = []\n",
        "\n",
        "for i in test_set:\n",
        "  f = extract_feature(i)\n",
        "  order.append(int(i.split(\"/\")[-1].split('.')[0]))\n",
        "  testset_features.append(f)\n",
        "\n",
        "len(testset_features), len(testset_features[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RZNe4jgC-1gx",
      "metadata": {
        "id": "RZNe4jgC-1gx"
      },
      "outputs": [],
      "source": [
        "testset_pred = rf_model.predict(testset_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lAhoBqrR-3nC",
      "metadata": {
        "id": "lAhoBqrR-3nC"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['Id'] = order\n",
        "submission['Label'] = testset_pred\n",
        "submission['Id'] = submission.Id.astype('int')\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1DBhs0L-6Wz",
      "metadata": {
        "id": "b1DBhs0L-6Wz"
      },
      "outputs": [],
      "source": [
        "submission.sort_values(by=['Id'],inplace=True)\n",
        "submission"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E7Xc5RUGqRYo",
      "metadata": {
        "id": "E7Xc5RUGqRYo"
      },
      "source": [
        "Change your labels to emotions for eg. `01 - sad` based on your label conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0892-Gk9-9Vw",
      "metadata": {
        "id": "0892-Gk9-9Vw"
      },
      "outputs": [],
      "source": [
        "emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59JY92d_-_0A",
      "metadata": {
        "id": "59JY92d_-_0A"
      },
      "outputs": [],
      "source": [
        "decode = dict(zip( emotions.values(), emotions.keys()))\n",
        "decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AODbpQpi_CFp",
      "metadata": {
        "id": "AODbpQpi_CFp"
      },
      "outputs": [],
      "source": [
        "submission['Label'] = submission.Label.replace(decode)\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oXjKSRMs_EXA",
      "metadata": {
        "id": "oXjKSRMs_EXA"
      },
      "outputs": [],
      "source": [
        "submission.to_csv(\"pred_submissions.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B8FnDiEQ_Hb0",
      "metadata": {
        "id": "B8FnDiEQ_Hb0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}