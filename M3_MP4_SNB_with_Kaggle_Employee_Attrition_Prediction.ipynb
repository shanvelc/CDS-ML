{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanvelc/CDS-ML/blob/main/M3_MP4_SNB_with_Kaggle_Employee_Attrition_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV8_Xueejdth"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Mini Project Notebook: Employee Attrition Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSHSzKp6j7zN"
      },
      "source": [
        "**DISCLAIMER:** THIS NOTEBOOK IS PROVIDED ONLY AS A REFERENCE SOLUTION NOTEBOOK FOR THE MINI-PROJECT. THERE MAY BE OTHER POSSIBLE APPROACHES/METHODS TO ACHIEVE THE SAME RESULTS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZlu0P9jj_ei"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xaJosu2kfGE"
      },
      "source": [
        "To predict employee attrition using CatBoost and XgBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N0iS4ipU_XM"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8OXq65pVDDS"
      },
      "source": [
        "At the end of the experiment, you will be able to\n",
        "\n",
        "* explore the employee attrition dataset\n",
        "* apply CatBoost and XgBoost on the dataset\n",
        "* tune the model hyperparameters to improve accuracy\n",
        "* evaluate the model using suitable metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYxPNsZuYcGk"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Employee attrition is the gradual reduction in employee numbers. Employee attrition happens when the size of your workforce diminishes over time. This means that employees are leaving faster than they are hired. Employee attrition happens when employees retire, resign, or simply aren't replaced.\n",
        "Although employee attrition can be company-wide, it may also be confined to specific parts of a business.\n",
        "\n",
        "Employee attrition can happen for several reasons. These include unhappiness about employee benefits or the pay structure, a lack of employee development opportunities, and even poor conditions in the workplace.\n",
        "\n",
        "To know more about the factors that lead to employee attrition, refer [here](https://www.betterup.com/blog/employee-attrition#:~:text=Employee%20attrition%20is%20the%20gradual,or%20simply%20aren't%20replaced).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsJP8R-j7tO8"
      },
      "source": [
        "**Gradient Boosted Decision Trees**\n",
        "\n",
        "* Gradient boosted decision trees (GBDTs) are one of the most important machine learning models.\n",
        "\n",
        "* GBDTs originate from AdaBoost, an algorithm that ensembles weak learners and uses the majority vote, weighted by their individual accuracy, to solve binary classification problems. The weak learners in this case are decision trees with a single split, called decision stumps.\n",
        "\n",
        "* Some of the widely used gradient boosted decision trees are XgBoost, CatBoost and LightGBM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC0AF58YH-cn"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset used for this mini-project is [HR Employee Attrition dataset](https://data.world/aaizemberg/hr-employee-attrition). It is a fictional dataset created by IBM data scientists. There are 35 features and 1470 records.\n",
        "\n",
        "There are numerical features such as:\n",
        "\n",
        "* Age\n",
        "* DistanceFromHome\n",
        "* EmployeeNumber\n",
        "* PerformanceRating\n",
        "\n",
        "There are several categorical features such as:\n",
        "* JobRole\n",
        "* EducationField\n",
        "* Department\n",
        "* BusinessTravel\n",
        "\n",
        "Dependent or target feature is 'attrition' which has values as Yes/No."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Kaggle Competition**"
      ],
      "metadata": {
        "id": "R1ZwUVHszG5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please refer to the link for viewing the\n",
        "[Kaggle Competition Document](https://drive.google.com/file/d/1eExeVCNdtblBWmtYJ3iNWboFzZbbfal4/view?usp=drive_link) and join the Kaggle Competition using the hyperlink given in this document under '*Kaggle* Competition site'."
      ],
      "metadata": {
        "id": "lC7IkM4qzMW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grading = 10 Points"
      ],
      "metadata": {
        "id": "tpO0w8WHzcCY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "812a816f"
      },
      "outputs": [],
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/hr_employee_attrition_train.csv\n",
        "print(\"Data Downloaded Successfuly!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BJzstlcLh4k"
      },
      "source": [
        "### Install CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYeUGMBZeqtL"
      },
      "outputs": [],
      "source": [
        "!pip -qq install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TmXyc2bRFvM"
      },
      "source": [
        "### Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v50DDzl0CEVk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier, metrics\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('display.max_columns', 100)\n",
        "%matplotlib inline\n",
        "\n",
        "from hyperopt import hp, tpe, Trials, STATUS_OK\n",
        "from hyperopt import fmin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXbWVHB9SdcT"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1: Read the dataset [0.5 Mark]**\n",
        "\n",
        "**Hint:** pd.read_csv()"
      ],
      "metadata": {
        "id": "7Rd78lhc369B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82VkFRBVSbG7"
      },
      "outputs": [],
      "source": [
        "ibm_df = pd.read_csv('/content/hr_employee_attrition_train.csv')\n",
        "ibm_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ibm_df.shape"
      ],
      "metadata": {
        "id": "bVeCLIvJBewV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ibm_df.over18.value_counts()"
      ],
      "metadata": {
        "id": "jMx3HQzey0YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ibm_df.employeecount.value_counts()"
      ],
      "metadata": {
        "id": "-4hRVdeixdPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above features that is employeecount and over18 has only one value throughout the records. Hence, they will be dropped.\n"
      ],
      "metadata": {
        "id": "Ry9NuJtG4Dfr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcIhPRvRNCtV"
      },
      "outputs": [],
      "source": [
        "ibm_df = ibm_df.drop(['employeenumber', 'employeecount','over18'], axis=1)\n",
        "ibm_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6QL6HbTZLjw"
      },
      "outputs": [],
      "source": [
        "# Shape of dataframe\n",
        "ibm_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JgkRXxYCEVn"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "- Check for missing values\n",
        "- Check for consistent data type across a feature\n",
        "- Check for outliers or inconsistencies in data columns\n",
        "- Check for correlated features\n",
        "- Do we have a target label imbalance\n",
        "- How our independent variables are distributed relative to our target label\n",
        "- Are there features that have strong linear or monotonic relationships, making correlation heatmaps makes it easy to identify possible colinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2: Create a `List` of numerical and categorical columns. Display a statistical description of the dataset. Remove missing values (if any) [0.5 Mark]**"
      ],
      "metadata": {
        "id": "oEL8X2-65Fm-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umiOV_elRr8O"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOHYyNvXRwHz"
      },
      "outputs": [],
      "source": [
        "description = pd.DataFrame(index=['observations(rows)', 'percent missing', 'dtype', 'range'])\n",
        "numerical = []\n",
        "categorical = []\n",
        "for col in ibm_df.columns:\n",
        "    obs = ibm_df[col].size\n",
        "    p_nan = round(ibm_df[col].isna().sum()/obs, 2)\n",
        "    num_nan = f'{p_nan}% ({ibm_df[col].isna().sum()}/{obs})'\n",
        "    dtype = 'categorical' if ibm_df[col].dtype == object else 'numerical'\n",
        "    numerical.append(col) if dtype == 'numerical' else categorical.append(col)\n",
        "    rng = f'{len(ibm_df[col].unique())} labels' if dtype == 'categorical' else f'{ibm_df[col].min()}-{ibm_df[col].max()}'\n",
        "    description[col] = [obs, num_nan, dtype, rng]\n",
        "\n",
        "#numerical.remove('employeecount')\n",
        "numerical.remove('standardhours')\n",
        "pd.set_option('display.max_columns', 100)\n",
        "display(description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5LDX4tYR6Vs"
      },
      "source": [
        "The data isn't missing any values and we can spend more time on comparing different gradient boosted tree algorithms. First, we want to get a sense of our data:\n",
        "- What features have the most divergent distributions based on target class\n",
        "- Do we have a target label imbalance\n",
        "- How our independent variables are distributed relative to our target label\n",
        "- Are there features that have strong linear or monotonic relationships, making correlation heatmaps makes it easy to identify possible colinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5mUbdCMKBP8"
      },
      "source": [
        "### Check for outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 3: Create a box plot to check for outliers [0.5 Mark]**"
      ],
      "metadata": {
        "id": "1MNRPwWS5S0n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYTxh7gtFqyC"
      },
      "outputs": [],
      "source": [
        "# Check for outliers\n",
        "ibm_df.boxplot(rot = 90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42cBMGHQQOWP"
      },
      "source": [
        "### Handing outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4: Use lower bound as 25% and upper bound as 75% to handle the outliers [0.5 Mark]**"
      ],
      "metadata": {
        "id": "FvNepmyD5e3V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT3yOFPoH0SH"
      },
      "outputs": [],
      "source": [
        "outlier_colms = ['monthlyincome', 'numcompaniesworked', 'stockoptionlevel',  'performancerating', 'totalworkingyears',\n",
        "                 'trainingtimeslastyear', 'yearsatcompany', 'yearsincurrentrole', 'yearssincelastpromotion', 'yearswithcurrmanager']\n",
        "ibm_df1 = ibm_df.copy()\n",
        "\n",
        "def handle_outliers(df, colm):\n",
        "    '''Change the values of outlier to upper and lower whisker values '''\n",
        "    q1 = df.describe()[colm].loc[\"25%\"]\n",
        "    q3 = df.describe()[colm].loc[\"75%\"]\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - (1.5 * iqr)\n",
        "    upper_bound = q3 + (1.5 * iqr)\n",
        "    for i in range(len(df)):\n",
        "        if df.loc[i,colm] > upper_bound:\n",
        "            df.loc[i,colm]= upper_bound\n",
        "        if df.loc[i,colm] < lower_bound:\n",
        "            df.loc[i,colm]= lower_bound\n",
        "    return df\n",
        "\n",
        "for colm in outlier_colms:\n",
        "    ibm_df1 = handle_outliers(ibm_df1, colm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvrMPhTtJTYP"
      },
      "outputs": [],
      "source": [
        "# Recheck for outliers\n",
        "ibm_df1.boxplot(rot = 90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ha6PPo2iCAM"
      },
      "source": [
        "### Target label imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 5: Check if there is an imbalance in target label [0.5 Mark]**"
      ],
      "metadata": {
        "id": "CrBnKrNa5ntR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1gsAjfLbi2Z"
      },
      "outputs": [],
      "source": [
        "# Count of unique values in Attrition column\n",
        "attrition_values = ibm_df1['attrition'].value_counts()\n",
        "attrition_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-8bU9moco7l"
      },
      "outputs": [],
      "source": [
        "# Plot barplot\n",
        "plt.bar(attrition_values.index, attrition_values.values)\n",
        "plt.title('IBM Attrition Label Imbalance')\n",
        "plt.xlabel('Whether IBM Employee Left')\n",
        "plt.ylabel('Count of Employees')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79pQoaQ3iOG7"
      },
      "source": [
        "###Plot pairplot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 6: Visualize the relationships between the predictor variables and the target variable using a pairplot [0.5 Mark]**"
      ],
      "metadata": {
        "id": "Ump6D_3g7txU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO9RJlfrCEVp"
      },
      "outputs": [],
      "source": [
        "# Visualize a pirplot with few feature\n",
        "features = ['monthlyincome', 'attrition', 'yearsatcompany', 'yearswithcurrmanager', 'joblevel', 'totalworkingyears']\n",
        "pairplot = sns.pairplot(ibm_df1[features], diag_kind='kde', hue='attrition')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC-FXYhIwNLw"
      },
      "source": [
        "From the results it can see that the data has an imbalance in target labels. It has about a 6:1 *No* attrition label compared to *Yes*. The effect of the imbalance really shows up in the pairplots where the *yes* markers in the scatter plots are all but drowned out, though this would be less of a problem if the classes were more distinct. To test the model a smart thing to do would be to look at the confusion matrix and see how well the model performed on the minority class, *yes*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVKpOQqPuyew"
      },
      "source": [
        "### Explore Correlation\n",
        "\n",
        "- Plotting the Heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 7: Visualize the correlation among IBM employee attrition numerical features using a heatmap [0.5 Mark]**"
      ],
      "metadata": {
        "id": "XAPt_vdC8X9y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC7eIV-P8rbX"
      },
      "outputs": [],
      "source": [
        "# Visualize heatmap\n",
        "plt.figure(figsize = (10, 8))\n",
        "numerical_ibm_df1 = ibm_df1.select_dtypes(include=['number'])\n",
        "sns.heatmap(numerical_ibm_df1.corr())\n",
        "plt.title('Correlation Among IBM Employee Attrition Numerical Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PTmvqIpCEVq"
      },
      "source": [
        "In the pairplot, from the diagonal distributions it seems that there are no features that have drastically different distributions between the classes.\n",
        "\n",
        "Lastly, plot the correlations between the features to look for colinear relationships. These are usually a problem for GBDTs but if there are many features with high correlation, some feature engineering can be done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etSGPdh6tp-D"
      },
      "source": [
        "### Preparing the Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation set\n",
        "train_ibm_df, test_ibm_df = train_test_split(ibm_df1, test_size = 0.05, stratify = ibm_df1['attrition'], random_state = 123)\n",
        "train_ibm_df.shape, test_ibm_df.shape"
      ],
      "metadata": {
        "id": "zGi4vBKCHNH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Attrition train\")\n",
        "print(train_ibm_df['attrition'].value_counts()/len(train_ibm_df))\n",
        "print(\"Attrition test\")\n",
        "print(test_ibm_df['attrition'].value_counts()/len(test_ibm_df))"
      ],
      "metadata": {
        "id": "SmCce9wEXXqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ibm_df.head()"
      ],
      "metadata": {
        "id": "ByimjVqHnL3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical"
      ],
      "metadata": {
        "id": "dXmbqGQsmfrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHqiWle6uzbR"
      },
      "outputs": [],
      "source": [
        "# Handling categorical features in test set\n",
        "test_dummy = pd.get_dummies(test_ibm_df[categorical], drop_first=True)\n",
        "test_dummy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOv8OYa1vJc6"
      },
      "outputs": [],
      "source": [
        "# Concat encoded features\n",
        "test_ibm_df = pd.concat([test_ibm_df, test_dummy], axis=1)\n",
        "# Drop original categorical columns\n",
        "test_ibm_df.drop(columns = categorical, inplace=True)\n",
        "test_ibm_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6WmbUykMGad"
      },
      "outputs": [],
      "source": [
        "# Rename target column\n",
        "test_ibm_df.rename(columns={'attrition_Yes': 'attrition'}, inplace=True)\n",
        "test_ibm_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykWxgJvOMGae"
      },
      "outputs": [],
      "source": [
        "# Features\n",
        "test_x = test_ibm_df.drop('attrition', axis=1)\n",
        "# Targer label\n",
        "test_y = test_ibm_df['attrition']\n",
        "\n",
        "test_x.shape, test_y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrBsGEleqeTf"
      },
      "source": [
        "# Hyperopt (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq5JX1LQqtOt"
      },
      "outputs": [],
      "source": [
        "def org_results(trials, hyperparams, model_name):\n",
        "    fit_idx = -1\n",
        "    for idx, fit  in enumerate(trials):\n",
        "        hyp = fit['misc']['vals']\n",
        "        xgb_hyp = {key:[val] for key, val in hyperparams.items()}\n",
        "        if hyp == xgb_hyp:\n",
        "            fit_idx = idx\n",
        "            break\n",
        "\n",
        "    train_time = str(trials[-1]['refresh_time'] - trials[0]['book_time'])\n",
        "    acc = round(trials[fit_idx]['result']['accuracy'], 3)\n",
        "    F1 = round(trials[fit_idx]['result']['f1 score'], 3)\n",
        "    train_auc = round(trials[fit_idx]['result']['train auc'], 3)\n",
        "    test_auc = round(trials[fit_idx]['result']['test auc'], 3)\n",
        "\n",
        "    results = {\n",
        "        'model': model_name,\n",
        "        'parameter search time': train_time,\n",
        "        'accuracy': acc,\n",
        "        'f1_score': F1,\n",
        "        'test auc score': test_auc,\n",
        "        'training auc score': train_auc,\n",
        "        'parameters': hyperparams\n",
        "    }\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional:\n",
        "Use `Hyperopt`, a hyperparameter tuning technique to identify the best set of parameters.\n",
        "\n",
        "Refer to the Additional Notebook: CatBoost parameter tuning [CDS-B8 GDrive -> Module 3 -> Assignments -> July 27, 2024 -> Additional Notebook (ungraded) -> Addl_NB_Tuning_hyerparameters_using_Hyperopt]"
      ],
      "metadata": {
        "id": "u1BAjyEZ_zHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the notebook, data processing is done separately for different models.\n",
        "Considering the fact that different models may require data in different format and in turn different processes may be followed to process the data.\n",
        "\n",
        "If the processing steps followed for the models are same, data processing can also be done once."
      ],
      "metadata": {
        "id": "-pggoL8s-Tr9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ccGpKffCEVt"
      },
      "source": [
        "## Apply CatBoost\n",
        "\n",
        "Catboost was released in 2017 by Yandex, showing, by their benchmark to be faster in prediction, better in accuracy, and easier to use for categorical data across a series of GBDT tasks.\n",
        "\n",
        "Additional capabilities of catboost include plotting feature interactions and object (row) importance.\n",
        "\n",
        "[Here](https://catboost.ai/en/docs/) is the official documentation of CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzFVwjSJ4Y4f"
      },
      "source": [
        "### Data Processing for CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 8: Data processing for CatBoost [1 Mark]**\n",
        "* **Copy the dataframe that was created after removing the outliers**\n",
        "* **Handle the categorical features if required**\n",
        "* **Create target column and feature space**"
      ],
      "metadata": {
        "id": "m6CuRppJ-lUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEvwzCDn4fSm"
      },
      "outputs": [],
      "source": [
        "cbo_data = train_ibm_df.copy()\n",
        "cbo_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8m66yjk4qZs"
      },
      "outputs": [],
      "source": [
        "# Handling categorical features in train set\n",
        "cbo_dummy = pd.get_dummies(cbo_data[categorical], drop_first=True)\n",
        "cbo_dummy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS-WzXpT5AZV"
      },
      "outputs": [],
      "source": [
        "# Concat the dummy variables to actual dataframe and remove initial categorical columns\n",
        "cbo_data = pd.concat([cbo_data, cbo_dummy], axis=1)\n",
        "cbo_data.drop(columns = categorical, inplace=True)\n",
        "cbo_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IN9qhNHB5fyt"
      },
      "outputs": [],
      "source": [
        "# Rename target column\n",
        "cbo_data.rename(columns={'attrition_Yes': 'attrition'}, inplace=True)\n",
        "cbo_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUA9-Dcy5sAe"
      },
      "outputs": [],
      "source": [
        "# Features\n",
        "x_df = cbo_data.drop('attrition', axis=1)\n",
        "# Targer label\n",
        "y_df = cbo_data['attrition']\n",
        "\n",
        "x_df.shape, y_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNebDYXzZSG_"
      },
      "source": [
        "### SMOTE (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFtKhVGYZQs7"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "x_df1, y_df1 = oversample.fit_resample(x_df, y_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjtd0Y7_Zfiy"
      },
      "outputs": [],
      "source": [
        "sns.countplot(y_df1, label = 'count')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After implementing SMOTE, x_df1 and y_df1 are the independent features and target labels simultaeneously.\n",
        "\n",
        "If SMOTE is to be applied they can be used while training the model."
      ],
      "metadata": {
        "id": "4s2jwg0O-vcx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Z0cbeS4BrT"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 9: Define, train the model and display the results [2 Mark]**"
      ],
      "metadata": {
        "id": "fBCh_75T_MRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer [here](https://catboost.ai/en/docs/concepts/speed-up-training) to see some ways to speedup CatBoost training."
      ],
      "metadata": {
        "id": "qKdR2vu2Ap6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dsLlj3-u8VH"
      },
      "outputs": [],
      "source": [
        "# def cat_objective(space):\n",
        "\n",
        "#     cboost = CatBoostClassifier(\n",
        "#     eval_metric  = 'AUC',\n",
        "#     learning_rate = space['learning_rate'],\n",
        "#     iterations = space['iterations'],\n",
        "#     depth = space['depth'],\n",
        "#     l2_leaf_reg = space['l2_leaf_reg'],\n",
        "#     border_count = space['border_count']\n",
        "#     )\n",
        "\n",
        "#     cboost.fit(x_df1, y_df1,\n",
        "#             cat_features=None)\n",
        "\n",
        "#     predictions = cboost.predict(test_x)\n",
        "#     test_preds = cboost.predict_proba(test_x)[:,1]\n",
        "#     train_preds = cboost.predict_proba(x_df1)[:,1]\n",
        "\n",
        "#     train_auc = roc_auc_score(y_df1, train_preds)\n",
        "#     test_auc = roc_auc_score(test_y, test_preds)\n",
        "#     accuracy = accuracy_score(test_y, predictions)\n",
        "#     F1 = f1_score(test_y, predictions)\n",
        "\n",
        "#     return {'status': STATUS_OK, 'loss': 1-test_auc, 'accuracy': accuracy,\n",
        "#             'test auc': test_auc, 'train auc': train_auc, 'f1 score': F1}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning technique to optimize parameters for CatBoost (Optional)."
      ],
      "metadata": {
        "id": "-DzLmk4f_eqk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD3PqPxXvk5x"
      },
      "outputs": [],
      "source": [
        "# trials = Trials()\n",
        "# space = {\n",
        "#     'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.3)),\n",
        "#     'iterations': hp.quniform('iterations', 25, 1000, 25),\n",
        "#     'depth': hp.quniform('depth', 1, 16, 1),\n",
        "#     'border_count': hp.quniform('border_count', 30, 220, 5),\n",
        "#     'l2_leaf_reg': hp.quniform('l2_leaf_reg', 1, 10, 1)\n",
        "# }\n",
        "\n",
        "# cboost_hyperparams = fmin(fn = cat_objective,\n",
        "#                  max_evals = 150,\n",
        "#                  trials = trials,\n",
        "#                  algo = tpe.suggest,\n",
        "#                  space = space\n",
        "#                  )\n",
        "\n",
        "# cbo_results = org_results(trials.trials, cboost_hyperparams, 'CatBoost')\n",
        "# display(cbo_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-OB_fA0Fsbv"
      },
      "outputs": [],
      "source": [
        "# Create CatBoost model\n",
        "cboost = CatBoostClassifier(learning_rate = 1,\n",
        "                            depth = 1,\n",
        "                            scale_pos_weight = 6,\n",
        "                            l2_leaf_reg = 8,\n",
        "                            border_count = 65)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cboost_dft = CatBoostClassifier()"
      ],
      "metadata": {
        "id": "oZLapfP-VQuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cboost_dft.fit(x_df, y_df, cat_features = None)"
      ],
      "metadata": {
        "id": "tG0Y2RGzVYRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apS4f8aqWG71"
      },
      "source": [
        "`Hyperopt`, hyperparameter tuning technique was used to identify the best set of parameters.\n",
        "* Different set of hyperparameters were giving good result.\n",
        "* Out of them, one such set was chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkRYWmGfDMu-"
      },
      "outputs": [],
      "source": [
        "# Model training\n",
        "cboost.fit(x_df, y_df, cat_features = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stov-GDTGrOw"
      },
      "source": [
        "### Model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k6sOOU-FNs7"
      },
      "outputs": [],
      "source": [
        "# Model performance on all sets\n",
        "predictions = cboost.predict(test_x)\n",
        "test_preds = cboost.predict_proba(test_x)[:,1]\n",
        "train_preds = cboost.predict_proba(x_df)[:,1]\n",
        "\n",
        "train_auc = roc_auc_score(y_df, train_preds)\n",
        "test_auc = roc_auc_score(test_y, test_preds)\n",
        "accuracy = accuracy_score(test_y, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y-o0nbfbCA8"
      },
      "source": [
        "F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RFXr_HZWTUE"
      },
      "outputs": [],
      "source": [
        "F1 = f1_score(test_y, predictions)\n",
        "print(F1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-86RxCFGbD_u"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_HOxtJpYJv1"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_y, predictions, labels=cboost.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=cboost.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance (Optional)"
      ],
      "metadata": {
        "id": "yuxtcfrxJgIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = x_df.columns\n",
        "importances_cboost = cboost.feature_importances_"
      ],
      "metadata": {
        "id": "Ay7vtWpjJpUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw1vWFt3bSrb"
      },
      "outputs": [],
      "source": [
        "cboost_results = {'accuracy': accuracy,\n",
        "                  'model': 'CatBoost',\n",
        "                  'f1_score': F1,\n",
        "                  'training auc score': train_auc,\n",
        "                  'test auc score': test_auc}\n",
        "cboost_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After removing those features.\n",
        "* f1 score fell below from 51 to 45.\n",
        "* Overfitting reduced."
      ],
      "metadata": {
        "id": "IYG3AIphiy22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-fold cross validation (Optional)"
      ],
      "metadata": {
        "id": "ummk1yZvwZti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use K-fold cross validation, training data file can be split into train and test sets using train_test_split method."
      ],
      "metadata": {
        "id": "T0C_gx46FEto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True)"
      ],
      "metadata": {
        "id": "EJdq7HBFwcis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, (train, test) in enumerate(kfold.split(x_df, y_df)):\n",
        "    cboost.fit(x_df.iloc[train], y_df.iloc[train])\n",
        "    print(f'iteration number = {k+1}')\n",
        "    print(f'Training Accuracy = {cboost.score(x_df.iloc[train], y_df.iloc[train])}')\n",
        "    print(f'Test Accuracy = {cboost.score(x_df.iloc[test], y_df.iloc[test])}')\n",
        "    print(f'f1 score = {f1_score(test_y, predictions)}')"
      ],
      "metadata": {
        "id": "g1ZlxQnqwjeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hk4Kw5QGXCU"
      },
      "source": [
        "## Apply XGBoost\n",
        "\n",
        "XGBoost is a workhorse gradient boosted decision tree algorithm. Its been around since 2014 and has come to dominate the Kaggle and data science community. XGB introduced gradient boosting where new models are fit to the residuals of prior models and then added together, using a gradient descent algorithm to minimize the loss.\n",
        "\n",
        "Read [here](https://xgboost.readthedocs.io/en/stable/parameter.html) on XGBoost parameters.\n",
        "\n",
        "Refer [here](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier) for the official documentation of XGBoost classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KbfDzqudx5H"
      },
      "source": [
        "### Data Processing for XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 10: Data Processing for XGBoost [1 Mark]**\n",
        "* **Copy the dataframe after the outliers were removed.**\n",
        "* **Handle the categorical features if required**\n",
        "* **Create target column and feature space**"
      ],
      "metadata": {
        "id": "SSzDQ0RmCcQd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT2RVw4JTAGp"
      },
      "outputs": [],
      "source": [
        "# Copy dataframe\n",
        "xgb_data = train_ibm_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX1wnlPFWViw"
      },
      "outputs": [],
      "source": [
        "# Handling categorical features\n",
        "xgb_dummy = pd.get_dummies(xgb_data[categorical], drop_first=True)\n",
        "xgb_dummy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-K7vfixWup8"
      },
      "outputs": [],
      "source": [
        "# Concat the dummy variables to actual dataframe and remove initial categorical columns\n",
        "xgb_data = pd.concat([xgb_data, xgb_dummy], axis=1)\n",
        "xgb_data.drop(columns = categorical, inplace=True)\n",
        "xgb_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCkr7gvLXxLs"
      },
      "outputs": [],
      "source": [
        "# Rename target column\n",
        "xgb_data.rename(columns={'attrition_Yes': 'attrition'}, inplace=True)\n",
        "xgb_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA-WIpLAX3KH"
      },
      "outputs": [],
      "source": [
        "# Features\n",
        "x_df = xgb_data.drop('attrition', axis=1)\n",
        "# Targer label\n",
        "y_df = xgb_data['attrition']\n",
        "\n",
        "x_df.shape, y_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOHyiq0zfLH7"
      },
      "outputs": [],
      "source": [
        "x_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhUCfdU8VoKl"
      },
      "source": [
        "Unlike LightGBM, in XGB, one has to manually create dummy variable/ label encoding for categorical features before feeding them into the models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SMOTE (Optional)"
      ],
      "metadata": {
        "id": "Qq91appDXiHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "x_df1, y_df1 = oversample.fit_resample(x_df, y_df)"
      ],
      "metadata": {
        "id": "sMLCPnvqXh2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(y_df1, label = 'count')"
      ],
      "metadata": {
        "id": "Jo_YccebXv0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccLyB9J04hDF"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 11: Define, train the model and display the results [2 Mark]**"
      ],
      "metadata": {
        "id": "BgMiG5XWCwgM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lAH1FBir1iA"
      },
      "outputs": [],
      "source": [
        "# def xgb_objective(space):\n",
        "\n",
        "#     model = XGBClassifier(\n",
        "#         learning_rate = space['learning_rate'],\n",
        "#         n_estimators = int(space['n_estimators']),\n",
        "#         max_depth = int(space['max_depth']),\n",
        "#         min_child_weight = space['m_child_weight'],\n",
        "#         gamma = space['gamma'],\n",
        "#         subsample = space['subsample'],\n",
        "#         scale_pos_weight = 6,\n",
        "#         colsample_bytree = space['colsample_bytree'],\n",
        "#         objective = 'binary:logistic'\n",
        "#     )\n",
        "\n",
        "#     model.fit(x_df, y_df)\n",
        "\n",
        "#     predictions = model.predict(test_x)\n",
        "#     test_preds = model.predict_proba(test_x)[:,1]\n",
        "#     train_preds = model.predict_proba(x_df)[:,1]\n",
        "\n",
        "#     xgb_booster = model.get_booster()\n",
        "#     train_auc = roc_auc_score(y_df, train_preds)\n",
        "#     test_auc = roc_auc_score(test_y, test_preds)\n",
        "#     accuracy = accuracy_score(test_y, predictions)\n",
        "#     F1 = f1_score(test_y, predictions)\n",
        "\n",
        "#     return {'status': STATUS_OK, 'loss': 1-test_auc, 'accuracy': accuracy,\n",
        "#             'test auc': test_auc, 'train auc': train_auc, 'f1 score': F1\n",
        "#            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USPd-eDhso_B"
      },
      "outputs": [],
      "source": [
        "space = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 1000, 25),\n",
        "    'max_depth': hp.quniform('max_depth', 1, 12, 1),\n",
        "    'm_child_weight': hp.quniform('m_child_weight', 1, 6, 1),\n",
        "    'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
        "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(.001), np.log(.3)),\n",
        "    'colsample_bytree': hp.quniform('colsample_bytree', .5, 1, .1)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBKOMQz3s3_7"
      },
      "outputs": [],
      "source": [
        "trials = Trials()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeO5MFXFurc1"
      },
      "outputs": [],
      "source": [
        "# xgb_results = org_results(trials.trials, xgb_hyperparams, 'XGBoost')\n",
        "# display(xgb_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxtvfYpzVxTc"
      },
      "outputs": [],
      "source": [
        "# Create XGBoost classifier model\n",
        "xgb_model = XGBClassifier(\n",
        "    learning_rate = 0.14972574734435318,\n",
        "    n_estimators = 200,\n",
        "    max_depth = 1,\n",
        "    min_child_weight = 6,\n",
        "    gamma = 0.5,\n",
        "    subsample = 0.55,\n",
        "    colsample_bytree = 1,\n",
        "    scale_pos_weight = 6,\n",
        "    objective = 'binary:logistic'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wab2IXllhA58"
      },
      "outputs": [],
      "source": [
        "x_df.shape, y_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrN85N3X_Sar"
      },
      "outputs": [],
      "source": [
        "xgb_model.fit(x_df, y_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model_dft = XGBClassifier()"
      ],
      "metadata": {
        "id": "9VziFsunVwi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model_dft.fit(x_df, y_df)"
      ],
      "metadata": {
        "id": "cmXb3eBHV0zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA5ZK31mPox1"
      },
      "source": [
        "### Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQXg9FhcmwIw"
      },
      "outputs": [],
      "source": [
        "# Model performance on all sets\n",
        "predictions = xgb_model.predict(test_x)\n",
        "test_preds = xgb_model.predict_proba(test_x)[:,1]\n",
        "train_preds = xgb_model.predict_proba(x_df)[:,1]\n",
        "\n",
        "xgb_booster = xgb_model.get_booster()\n",
        "\n",
        "train_auc = roc_auc_score(y_df, train_preds)\n",
        "test_auc = roc_auc_score(test_y, test_preds)\n",
        "accuracy = accuracy_score(test_y, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjWW7nHEbYjj"
      },
      "source": [
        "F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W0e4fAGa4cc"
      },
      "outputs": [],
      "source": [
        "F1 = f1_score(test_y, predictions)\n",
        "print(F1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs9NOq5ubcwZ"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz_HcDDCblQH"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_y, predictions, labels=cboost.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=cboost.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importance"
      ],
      "metadata": {
        "id": "uLrUrazNHWo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = x_df.columns\n",
        "importances_xgboost = xgb_model.feature_importances_"
      ],
      "metadata": {
        "id": "VGrs1D4WHVp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb6aCcudbxzg"
      },
      "outputs": [],
      "source": [
        "xgb_results = {'accuracy': accuracy,\n",
        "              'model': 'XGBoost',\n",
        "              'f1_score': F1,\n",
        "              'test auc score': test_auc,\n",
        "              'training auc score': train_auc}\n",
        "xgb_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f1 score fell below, from 51 to 50.\n",
        "* Overfitting is unaffected."
      ],
      "metadata": {
        "id": "_j6Xz7k7jOXK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Iki__IJCEVs"
      },
      "source": [
        "## Apply LightGBM (Optional)\n",
        "\n",
        "LightGBM is an open-source GBDT framework created by Microsoft as a fast and scalable alternative to XGB and GBM. By default LightGBM will train a Gradient Boosted Decision Tree (GBDT), but it also supports random forests, Dropouts meet Multiple Additive Regression Trees (DART), and Gradient Based One-Side Sampling (Goss).\n",
        "\n",
        "To know more about LightGBM parameters, refer [here](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGVwrT59tEx_"
      },
      "source": [
        "### Feature Engineering for LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Following the same procedure as followed in XGBoost\n",
        "\n",
        "# Copy the dataframe\n",
        "lgb_data = train_ibm_df.copy()\n",
        "\n",
        "# Handling categorical features\n",
        "lgb_dummy = pd.get_dummies(lgb_data[categorical], drop_first=True)\n",
        "\n",
        "# Concat the dummy variables to actual dataframe and remove initial categorical columns\n",
        "lgb_data = pd.concat([lgb_dummy, lgb_data], axis=1)\n",
        "lgb_data.drop(columns = categorical, inplace=True)\n",
        "\n",
        "# Rename target column\n",
        "lgb_data.rename(columns={'attrition_Yes': 'attrition'}, inplace=True)\n",
        "\n",
        "# Features\n",
        "x_df = lgb_data.drop(columns='attrition')\n",
        "# Target lebel\n",
        "y_df = lgb_data['attrition'].reset_index(drop=True)\n",
        "x_df.shape, y_df.shape"
      ],
      "metadata": {
        "id": "CGGock_zP806"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYq9Z02Bs4-x"
      },
      "outputs": [],
      "source": [
        "# SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "x_df1, y_df1 = oversample.fit_resample(x_df, y_df)\n",
        "sns.countplot(y_df1, label = 'count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNxN3-gU4ZWn"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9Z1PzRh1kC-"
      },
      "outputs": [],
      "source": [
        "def lgb_objective(space):\n",
        "\n",
        "    lgbm = LGBMClassifier(\n",
        "        learning_rate = space['learning_rate'],\n",
        "        n_estimators= int(space['n_estimators']),\n",
        "        max_depth = int(space['max_depth']),\n",
        "        num_leaves = int(space['num_leaves']),\n",
        "        colsample_bytree = space['colsample_bytree'],\n",
        "        feature_fraction = space['feature_fraction'],\n",
        "        scale_pos_weight = 5,\n",
        "        reg_lambda = space['reg_lambda'],\n",
        "        reg_alpha = space['reg_alpha'],\n",
        "        min_split_gain = space['min_split_gain']\n",
        "    )\n",
        "\n",
        "    lgbm.fit(x_df, y_df)\n",
        "\n",
        "    predictions = lgbm.predict(test_x)\n",
        "    test_preds = lgbm.predict_proba(test_x)[:,1]\n",
        "    train_preds = lgbm.predict_proba(x_df)[:,1]\n",
        "\n",
        "    train_auc = roc_auc_score(y_df, train_preds)\n",
        "    test_auc = roc_auc_score(test_y, test_preds)\n",
        "    accuracy = accuracy_score(test_y, predictions)\n",
        "    F1 = f1_score(test_y, predictions)\n",
        "\n",
        "    return {'status': STATUS_OK, 'loss': 1-test_auc, 'accuracy': accuracy,\n",
        "            'test auc': test_auc, 'train auc': train_auc, 'f1 score': F1\n",
        "\n",
        "           }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di89aY0V1-j2"
      },
      "outputs": [],
      "source": [
        "trials = Trials()\n",
        "space = {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.3)),\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 1200, 25),\n",
        "    'max_depth': hp.quniform('max_depth', 1, 15, 1),\n",
        "    'num_leaves': hp.quniform('num_leaves', 10, 150, 1),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
        "    'feature_fraction': hp.uniform('feature_fraction', .3, 1.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
        "    'min_split_gain': hp.uniform('min_split_gain', 0.0001, 0.1)\n",
        "}\n",
        "\n",
        "lgb_hyperparams = fmin(fn = lgb_objective,\n",
        "                 max_evals = 5,\n",
        "                 trials = trials,\n",
        "                 algo = tpe.suggest,\n",
        "                 space = space\n",
        "                 )\n",
        "\n",
        "lgb_results = org_results(trials.trials, lgb_hyperparams, 'LightGBM')\n",
        "display(lgb_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHAiruTHJ6e2"
      },
      "outputs": [],
      "source": [
        "# # Create LightGBM classifier model\n",
        "# lgbm = LGBMClassifier(\n",
        "#     learning_rate = 0.15828893812295405,\n",
        "#     n_estimators= 825,\n",
        "#     max_depth = 8,\n",
        "#     num_leaves = 110,\n",
        "#     colsample_bytree = 0.6839759118900923,\n",
        "#     feature_fraction = 0.3930665137463929,\n",
        "#     reg_lambda = 0.8857198279892347,\n",
        "#     reg_alpha = 0.8003856547872137,\n",
        "#     min_split_gain = 0.07737786522996747\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fWl23dHXHAP"
      },
      "outputs": [],
      "source": [
        "# Create LightGBM classifier model\n",
        "lgbm = LGBMClassifier(\n",
        "    learning_rate = 1,\n",
        "    n_estimators= 100,\n",
        "    max_depth = 3,\n",
        "    num_leaves = 31,\n",
        "    colsample_bytree = 1,\n",
        "    reg_lambda = 30,\n",
        "    scale_pos_weight = 5,\n",
        "    reg_alpha = 30,\n",
        "    min_split_gain = 3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FktD02ntN1T"
      },
      "outputs": [],
      "source": [
        "lgbm.fit(x_df, y_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_dft = LGBMClassifier()"
      ],
      "metadata": {
        "id": "E19gNKLEWABb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_dft.fit(x_df, y_df)"
      ],
      "metadata": {
        "id": "Jl312goTWCni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upM6hxP_SbPw"
      },
      "source": [
        "### Model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmM2WvTGSd_l"
      },
      "outputs": [],
      "source": [
        "# Model performance on all sets\n",
        "predictions = lgbm.predict(test_x)\n",
        "test_preds = lgbm.predict_proba(test_x)[:,1]\n",
        "train_preds = lgbm.predict_proba(x_df1)[:,1]\n",
        "\n",
        "train_auc = roc_auc_score(y_df1, train_preds)\n",
        "test_auc = roc_auc_score(test_y, test_preds)\n",
        "accuracy = accuracy_score(test_y, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pglve22Bb-qX"
      },
      "source": [
        "F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj0eWBLocDPQ"
      },
      "outputs": [],
      "source": [
        "F1 = f1_score(test_y, predictions)\n",
        "print(F1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P9aaTvRcIRw"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfYICC51cL83"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_y, predictions, labels=cboost.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=cboost.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance"
      ],
      "metadata": {
        "id": "xFeqXlHsIjPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = x_df.columns\n",
        "importances_lgbm = lgbm.feature_importances_"
      ],
      "metadata": {
        "id": "UWg8wzEQItWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMNhQAymdrRK"
      },
      "outputs": [],
      "source": [
        "lgbm_results = {'accuracy': accuracy,\n",
        "              'model': 'LightGBM',\n",
        "              'f1_score': F1,\n",
        "              'test auc score': test_auc,\n",
        "              'training auc score': train_auc}\n",
        "\n",
        "lgbm_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f1 score drastically fell.\n",
        "* Overfiiting is unaffected."
      ],
      "metadata": {
        "id": "m1VAxCYxjeiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importances Dataframe"
      ],
      "metadata": {
        "id": "xITfGpEuK3s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances_cboost"
      ],
      "metadata": {
        "id": "2bmHAiENbVYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.round(importances_xgboost*100))"
      ],
      "metadata": {
        "id": "tE1QtNszbcm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances_lgbm"
      ],
      "metadata": {
        "id": "p1T3Mr3DbgoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.round(importances_cboost))"
      ],
      "metadata": {
        "id": "d_wJlw-rbMF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances_df = pd.DataFrame()\n",
        "importances_df['Feature Name'] = features\n",
        "importances_df['Feature Imp CBoost'] = np.round(importances_cboost)\n",
        "importances_df['Feature Imp XGBoost'] = np.round(importances_xgboost*100)\n",
        "importances_df['Feature Imp LightBoost'] = importances_lgbm\n",
        "importances_df.sort_values(['Feature Imp CBoost', 'Feature Imp XGBoost', 'Feature Imp LightBoost'], ascending=False)"
      ],
      "metadata": {
        "id": "o1-IDjd6Kt86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18zLjk0qCEVu"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 12: Create a dataframe of XGBoost results, LightGBM results, CatBoost results and display them [0.5 Mark]**"
      ],
      "metadata": {
        "id": "uGKviu5FD4RX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFGMmqS-CEVu"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe for computed metrics for different models\n",
        "final_results = pd.DataFrame([xgb_results, lgbm_results, cboost_results])\n",
        "display(final_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMf8Z8h4Tt3E"
      },
      "source": [
        "- XGBoost is a wonderful algorithm with great documentation and many examples from years of use.\n",
        "- LightGBM was clearly the fastest algorithm, often being 10x faster than XGBoost.\n",
        "- In terms of accuracy the test and train dataset often had different balances of minority and majority class so 1-to-1 comparisons aren't perfect.\n",
        "- CatBoost was the algorithm one can be most interested in using because of the supposed innovations in working with categorical data. Despite good accuracy however, several problems were faced.\n",
        "\n",
        "    - CatBoost seemed significantly slower than the other algorithms, it seemed to stall on some evaluations. More experimentation may be needed with CatBoost and data that had lots of categorical features to get a better feel for when it may perform best."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* SMOTE was used to handle imabalance, it had no effect on the performance of all the three models.\n",
        "* Using POS weight parameter to handle imabalace in all the three models helps give good results.\n",
        "* K-fold cross validation technique was used while using train test split, performance of the model dipped.\n",
        "* Outliers were handled but it had least effect on the performance.\n",
        "* Three irrelevant features were dropped, it had no effect on the model performance.\n",
        "* By far CatBoost is the best performing model followed by XGBoost whereas CatBoost takes longer to optimize parameters using Hyperopt, it is quick with XGBoost.\n",
        "* Feature importance was calculated for all the three models.\n",
        "* Based upon the importance 5 features were identified as not important. Removing these features while training dipped the performance of the models."
      ],
      "metadata": {
        "id": "rBzRklem4b2B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWJ9p6CSfxAH"
      },
      "source": [
        "References:\n",
        "1. https://machinelearningmastery.com/xgboost-for-imbalanced-classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle Prediction"
      ],
      "metadata": {
        "id": "BRr_TJjfDosO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data from Kaggle competition site"
      ],
      "metadata": {
        "id": "0-WdkpdE4T8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_test = pd.read_csv(\"/content/hr_employee_attrition_test.csv\")\n",
        "kaggle_test.head()"
      ],
      "metadata": {
        "id": "wVaaf4c84e0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_test.shape"
      ],
      "metadata": {
        "id": "17zkutHAEYeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEt8xjHGk3OH"
      },
      "outputs": [],
      "source": [
        "# Drop columns having single value\n",
        "test_df = kaggle_test.drop(['id','employeenumber', 'employeecount', 'over18'], axis=1)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "JNkRr1ZgRrqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical"
      ],
      "metadata": {
        "id": "yEfAls7jIBHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW-6JXPZIBHr"
      },
      "outputs": [],
      "source": [
        "# Handling categorical features\n",
        "dummy = pd.get_dummies(test_df[categorical[:7]], drop_first=True)\n",
        "dummy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9UgkmvYIBHs"
      },
      "outputs": [],
      "source": [
        "# Concat the dummy variables to actual dataframe and remove initial categorical columns\n",
        "test_df1 = pd.concat([test_df, dummy], axis=1)\n",
        "test_df1.drop(columns = categorical[:7], inplace=True)\n",
        "test_df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXdyPoJQIBHs"
      },
      "outputs": [],
      "source": [
        "test_df1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions"
      ],
      "metadata": {
        "id": "j4JsPbgRSnz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cboost_preds = cboost.predict(test_df1)\n",
        "cboost_preds"
      ],
      "metadata": {
        "id": "21NdCOX6Dqsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_preds = xgb_model.predict(test_df1)\n",
        "xgb_preds"
      ],
      "metadata": {
        "id": "LC00_oIRS5Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_preds = lgbm.predict(test_df1)\n",
        "lgbm_preds"
      ],
      "metadata": {
        "id": "wpAWgoOgS_zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save predictions to csv"
      ],
      "metadata": {
        "id": "4atWdUdYTKKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_df = pd.DataFrame({'id': kaggle_test['id'],\n",
        "                        'label': cboost_preds})\n",
        "save_df.head()"
      ],
      "metadata": {
        "id": "2fdCHZ-jTF7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_df.to_csv(\"predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "NmwDZWemTabD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_truth = pd.read_csv(\"/content/ground_truth.csv\")\n",
        "g_truth.head()"
      ],
      "metadata": {
        "id": "hYy1RZaUUgJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(g_truth.label, cboost_preds)"
      ],
      "metadata": {
        "id": "IMI7OUMoUprp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(g_truth.label, xgb_preds)"
      ],
      "metadata": {
        "id": "buxPR6-hU09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(g_truth.label, lgbm_preds)"
      ],
      "metadata": {
        "id": "Ef1JTIRiU39P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(g_truth.label, cboost_dft.predict(test_df1))"
      ],
      "metadata": {
        "id": "scstiGp5WGeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(g_truth.label, xgb_model_dft.predict(test_df1))"
      ],
      "metadata": {
        "id": "JtJSe24vWSy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(g_truth.label, lgbm_dft.predict(test_df1))"
      ],
      "metadata": {
        "id": "QpElaUIdWXlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PouVMRCWWZZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}