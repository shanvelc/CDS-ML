{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanvelc/CDS-ML/blob/main/M3_AST_07_Catboost_XGBoost_LightGBM_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "\n",
        "##  A program by IISc and TalentSprint\n",
        "\n",
        "### Assignment: Catboost, XGBoost and LightGBM"
      ],
      "metadata": {
        "id": "hHK2aNWllxgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives\n",
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* perform data preprocessing\n",
        "* perform feature transformation\n",
        "* implement CatBoost, XGBoost and LightGBM model to perform classification using Lending Club dataset"
      ],
      "metadata": {
        "id": "rPb4uAvol56w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Walkthrough Video\n",
        "from IPython.display import HTML\n",
        "HTML(\"\"\"<video width=\"420\" height=\"240\" controls>\n",
        "<source src=\"https://cdn.chn.talentsprint.com/content/CatBoost_LightGBM_XGBoost.mp4\">\n",
        "</video>\"\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "agKkJeqbUxJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "**XGBoost** was originally produced by University of Washington researchers and is maintained by open-source contributors. XGBoost is available in Python, R, Java, Ruby, Swift, Julia, C, and C++. Similar to LightGBM, XGBoost uses the gradients of different cuts to select the next cut, but XGBoost also uses the hessian, or second derivative, in its ranking of cuts. Computing this next derivative comes at a slight cost, but it also allows a greater estimation of the cut to use.\n",
        "\n",
        "**CatBoost** is developed and maintained by the Russian search engine Yandex and is available in Python, R, C++, Java, and also Rust. CatBoost distinguishes itself from LightGBM and XGBoost by focusing on optimizing decision trees for categorical variables, or variables whose different values may have no relation with each other (eg. apples and oranges).\n",
        "\n",
        "**LightGBM** is a boosting technique and framework developed by Microsoft. The framework implements the LightGBM algorithm and is available in Python, R, and C. LightGBM is unique in that it can construct trees using Gradient-Based One-Sided Sampling, or GOSS for short.\n",
        "\n",
        "To know more on comparisons between CatBoost, XgBoost and LightGBM, refer below\n",
        "- [Article 1](https://cdn.iisc.talentsprint.com/CDS/Assignments/Module2/catboost%20vs%20lightgbm%20vs%20xgboost.pdf)\n",
        "- [Article 2](https://cdn.iisc.talentsprint.com/CDS/Assignments/Module2/catboost%20lightgbm%20xgboost%202.pdf)"
      ],
      "metadata": {
        "id": "X50WsN2yl9kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Description\n",
        "\n",
        "Lending Club is a lending platform that lends money to people in need at an interest rate based on their credit history and other factors. We will analyze this data and pre-process it based on our need and build a machine learning model that can identify a potential defaulter based on his/her history of transactions with Lending Club.\n",
        "\n",
        "This dataset contains 42538 rows and 144 columns. **Out of these 144 columns, many columns have majorly null values.**\n",
        "\n",
        "To know more about the Lending Club dataset features, refer [here](https://www.openintro.org/data/index.php?data=loans_full_schema)."
      ],
      "metadata": {
        "id": "0lGO-OJgmCar"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M3_AST_07_Catboost_XGBoost_LightGBM_B\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/CDS/Datasets/LoanStats3a.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://cds-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Import required packages"
      ],
      "metadata": {
        "id": "7HLNGs_bmHvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qq install catboost"
      ],
      "metadata": {
        "id": "6AyEiRD66zJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7hZ-QMJcOs3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ],
      "metadata": {
        "id": "JbSh_Jq2oWY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the raw loan stats dataset\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "y3xYi3z2cS7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "E4dwETB2_8Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the top 5 rows of data\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "3XE_8K_3d2n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of the dataset\n",
        "data.shape"
      ],
      "metadata": {
        "id": "36p-CTA3d6DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking info of the raw dataframe\n",
        "data.info()"
      ],
      "metadata": {
        "id": "rzpIimAdd8qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check for missing values in the dataset"
      ],
      "metadata": {
        "id": "zlFPKYZucnF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "BP75_3EveDF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total percentage of null values in the data\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "VftRYeN1eFJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above we can see that, about 63% of the values in the overall data are null values.\n",
        "\n",
        "Let's visualize the null values using the heatmap."
      ],
      "metadata": {
        "id": "VLaMMhLJoeyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for null values using a heatmap as a visualizing tool\n",
        "plt.figure(figsize=(16,14))\n",
        "sns.heatmap(data.isnull())\n",
        "plt.title('Null values heat plot', fontdict={'fontsize': 20})\n",
        "plt.legend(data.isnull())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V4BNkjPveZ67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the above heatmap, there are lot of null values in the dataset. We have to carefully deal with these null values."
      ],
      "metadata": {
        "id": "zURs_QrsokZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling missing values in the data\n",
        "\n",
        "- Select columns having null values less than 40%"
      ],
      "metadata": {
        "id": "OjIX4nb0haL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe to display percentage of null values in different number of columns\n",
        "temp_df = pd.DataFrame()\n",
        "temp_df['Percentage of null values'] = ['10% or less', '10% to 20%', '20% to 30%', '30% to 40%', '40% to 50%',\n",
        "                                        '50% to 60%', '60% to 70%', '70% to 80%', '80% to 90%', 'More than 90%']\n",
        "\n",
        "# Store the columns count separately for each range\n",
        "ten_percent = len(data.columns[((data.isnull().sum())/len(data)) <= 0.1])\n",
        "\n",
        "ten_to_twenty_percent = len(data.columns[((data.isnull().sum() / len(data)) > 0.1) & ((data.isnull().sum() / len(data)) <= 0.2)])\n",
        "\n",
        "twenty_to_thirty_percent = len(data.columns[((data.isnull().sum() / len(data)) > 0.2) & ((data.isnull().sum() / len(data)) <= 0.3)])\n",
        "\n",
        "thirty_to_forty_percent = len(data.columns[((data.isnull().sum() / len(data)) > 0.3) & ((data.isnull().sum() / len(data)) <= 0.4)])\n",
        "\n",
        "forty_to_fifty_percent = len(data.columns[((data.isnull().sum() / len(data)) > 0.4) & ((data.isnull().sum() / len(data)) <= 0.5)])\n",
        "\n",
        "fifty_to_sixty_percent = len(data.columns[((data.isnull().sum() / len(data)) > 0.5) & ((data.isnull().sum() / len(data)) <= 0.6)])\n",
        "\n",
        "sixty_to_seventy_percent = len(data.columns[((data.isnull().sum() / len(data)) > 0.6) & ((data.isnull().sum() / len(data)) <= 0.7)])\n",
        "\n",
        "seventy_to_eighty_percent = len(data.columns[((data.isnull().sum() / len(data)) > 0.7) & ((data.isnull().sum() / len(data)) <= 0.8)])\n",
        "\n",
        "eighty_to_ninety_percent = len(data.columns[((data.isnull().sum() / len(data)) > 0.8) & ((data.isnull().sum() / len(data)) <= 0.9)])\n",
        "hundred_percent = len(data.columns[((data.isnull().sum())/len(data)) > 0.9])\n",
        "\n",
        "temp_df['No. of columns'] = [ten_percent, ten_to_twenty_percent, twenty_to_thirty_percent, thirty_to_forty_percent, forty_to_fifty_percent,\n",
        "                             fifty_to_sixty_percent, sixty_to_seventy_percent, seventy_to_eighty_percent, eighty_to_ninety_percent, hundred_percent]\n",
        "temp_df"
      ],
      "metadata": {
        "id": "FBImOzigeI6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above results, we can see that there are only 53 columns out of 144 columns that have null values less than 40%."
      ],
      "metadata": {
        "id": "hHS5BcqvlQ-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Considering only those columns which have null values less than 40% in that particular column\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "2mHQkFItl8rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By considering columns with less number of null values, we were able to decrease total number of columns from 144 to 53.\n",
        "\n",
        "Note that we will deal with null values present in these selected 53 columns later below."
      ],
      "metadata": {
        "id": "liBwKqkZoqIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing columns having single distinct value"
      ],
      "metadata": {
        "id": "KJzVNT2ao7-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking columns that have only single values in them i.e, constant columns\n",
        "const_cols = []\n",
        "for i in df1.columns:\n",
        "    if df1[i].nunique() == 1:\n",
        "        const_cols.append(i)\n",
        "\n",
        "print(const_cols)"
      ],
      "metadata": {
        "id": "cxs3ijWIsWkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After observing the above output, we are dropping columns which have single values in them\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "5vmDkStNezn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract features from datetime columns"
      ],
      "metadata": {
        "id": "-Lol-fG96tXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns other than numerical value\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "a_vwXKHACYO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which columns needs to be converted to datetime\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "o8iRbXj0DJpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting objects to datetime columns\n",
        "dt_cols = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'last_credit_pull_d']\n",
        "for i in dt_cols:\n",
        "    df1[i] = pd.to_datetime(df1[i].astype('str'), format='%b-%y', yearfirst=False)"
      ],
      "metadata": {
        "id": "NRP62kpEf7ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the new datetime columns\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "i-r3ih0af9sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Considering only year of joining for 'earliest_cr_line' column\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ZrLCH2kBf_uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding new features by getting month and year from [issue_d, last_pymnt_d, and last_credit_pull_d] columns\n",
        "df1['issue_d_year'] = pd.DatetimeIndex(df1['issue_d']).year\n",
        "df1['issue_d_month'] = pd.DatetimeIndex(df1['issue_d']).month\n",
        "df1['last_pymnt_d_year'] = pd.DatetimeIndex(df1['last_pymnt_d']).year\n",
        "df1['last_pymnt_d_month'] = pd.DatetimeIndex(df1['last_pymnt_d']).month\n",
        "df1['last_credit_pull_d_year'] = pd.DatetimeIndex(df1['last_credit_pull_d']).year\n",
        "df1['last_credit_pull_d_month'] = pd.DatetimeIndex(df1['last_credit_pull_d']).month"
      ],
      "metadata": {
        "id": "-jZAP_xEE20T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction\n",
        "df1.earliest_cr_line = 2019 - (df1.earliest_cr_line)\n",
        "df1.issue_d_year = 2019 - (df1.issue_d_year)\n",
        "df1.last_pymnt_d_year = 2019 - (df1.last_pymnt_d_year)\n",
        "df1.last_credit_pull_d_year = 2019 - (df1.last_credit_pull_d_year)"
      ],
      "metadata": {
        "id": "SrE98buOgCQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the original features to avoid data redundancy\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "H3TnPu4NFJSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check for missing values in reduced dataset"
      ],
      "metadata": {
        "id": "iL0BKtxmHDsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for null values in the updated dataframe\n",
        "plt.figure(figsize=(16,10))\n",
        "sns.heatmap(df1.isnull())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "usuwpFVdHDsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Null values in reduced dataset"
      ],
      "metadata": {
        "id": "BOe_jJNepdO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for Percentage of null values\n",
        "a = (df1.isnull().sum() / df1.shape[0]) * 100\n",
        "b = a[a > 0.00]\n",
        "b = pd.DataFrame(b, columns = ['Percentage of null values'])\n",
        "b.sort_values(by= ['Percentage of null values'], ascending=False)"
      ],
      "metadata": {
        "id": "ugEBAAZ0gfG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the 29 rows which have null values in few columns\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "X9QB5SQxgiBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking again for Percentage of null values\n",
        "a = (df1.isnull().sum() / df1.shape[0]) * 100\n",
        "b = a[a > 0.00]\n",
        "b = pd.DataFrame(b, columns = ['Percentage of null values'])\n",
        "b.sort_values(by= ['Percentage of null values'], ascending=False)"
      ],
      "metadata": {
        "id": "xNlwQrJDJPMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, imputing the missing values with the median value for columns **'last_pymnt_d_year', 'last_pymnt_d_month', 'last_credit_pull_d_year', 'last_credit_pull_d_month', 'tax_liens'** as null values in these columns are less than 0.5% of the size."
      ],
      "metadata": {
        "id": "oEqh3yJdJoQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputing the null values with the median value\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Unmqrawtg5RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For **'revol_util'** column, filling null values with median(string) which is close to 50:"
      ],
      "metadata": {
        "id": "sC2UBoI6O2hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For 'revol_util' column, fill null values with 50%\n",
        "df1.revol_util.fillna('50%', inplace=True)\n",
        "\n",
        "# Extracting numerical value from string\n",
        "df1.revol_util = df1.revol_util.apply(lambda x: x[:-1])\n",
        "\n",
        "# Converting string to float\n",
        "df1.revol_util = df1.revol_util.astype('float')"
      ],
      "metadata": {
        "id": "GS2kqG36g8cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique values in 'pub_rec_bankruptcies' column\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "gekyufGcg-6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above we can see that the **'pub_rec_bankruptcies'** column is highly imbalanced. So, it is better to fill it with median(0) value as even after building model the model will be skewed very much towards 0."
      ],
      "metadata": {
        "id": "3cwz3slEOL2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill 'pub_rec_bankruptcies' column\n",
        "df1['pub_rec_bankruptcies'].fillna(df1['pub_rec_bankruptcies'].median(), inplace=True)"
      ],
      "metadata": {
        "id": "6AWWxks-hBdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique values in 'emp_length' column\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "SojmtM3vPS60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperating null values by assigning a random string\n",
        "df1['emp_length'].fillna('5000',inplace=True)\n",
        "\n",
        "# Filling '< 1 year' as '0 years' of experience and '10+ years' as '10 years'\n",
        "df1.emp_length.replace({'10+ years':'10 years', '< 1 year':'0 years'}, inplace=True)\n",
        "\n",
        "# Then extract numerical value from the string\n",
        "df1.emp_length = df1.emp_length.apply(lambda x: x[:2])\n",
        "\n",
        "# Converting it's dattype to float\n",
        "df1.emp_length = df1.emp_length.astype('float')"
      ],
      "metadata": {
        "id": "YcWgdDHAhFlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking again for Percentage of null values\n",
        "a = (df1.isnull().sum() / df1.shape[0]) * 100\n",
        "b = a[a > 0.00]\n",
        "b = pd.DataFrame(b, columns = ['Percentage of null values'])\n",
        "b.sort_values(by= ['Percentage of null values'], ascending=False)"
      ],
      "metadata": {
        "id": "E9hVvsC-Qd76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing redundant features and features which have percentage null values > 5%\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "uwKagHxGQjjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting categorical columns to numerical columns\n"
      ],
      "metadata": {
        "id": "-0aK6n8ipQkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(2)"
      ],
      "metadata": {
        "id": "8sNrHRi4RXr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique values in 'term' column\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "hmWuPYAjTTEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique values in 'int_rate' column\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "YBl7Ure7TssE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting 'term' and 'int_rate' to numerical columns\n",
        "df1.term = df1.term.apply(lambda x: x[1:3])\n",
        "df1.term = df1.term.astype('float')\n",
        "df1.int_rate = df1.int_rate.apply(lambda x: x[:2])\n",
        "df1.int_rate = df1.int_rate.astype('float')\n",
        "df1.head(2)"
      ],
      "metadata": {
        "id": "TgEc_S7xgKvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among the address related features, considering **'addr_state'** column and excluding **'zip_code'** column."
      ],
      "metadata": {
        "id": "jRoioVr0Wj_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.drop('zip_code', axis = 1)"
      ],
      "metadata": {
        "id": "AFHRmxU2WjbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding on categorical columns\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "JrfQzmiAgNTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding on 'grade' column\n",
        "le = LabelEncoder()\n",
        "le.fit(df2.grade)\n",
        "print(le.classes_)"
      ],
      "metadata": {
        "id": "QtwLraNPgQhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 'grade' column\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "OWgdfHRygSuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding on 'sub_grade' column\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "J0M83a0JgUsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 'sub_grade' column\n",
        "df2.sub_grade = le2.transform(df2.sub_grade)"
      ],
      "metadata": {
        "id": "VgnXJHMMgWqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head(2)"
      ],
      "metadata": {
        "id": "e5cFVIBtVmXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target feature\n",
        "df2['loan_status'].unique()"
      ],
      "metadata": {
        "id": "n6K3hxCUhLtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction features\n",
        "X = df2.drop(\"loan_status\", axis = 1)\n",
        "# Target variable\n",
        "y = df2['loan_status']\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "uWy6a5-cho6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding the target variable\n",
        "le3 = LabelEncoder()\n",
        "le3.fit(y)\n",
        "y_transformed = le3.transform(y)\n",
        "y_transformed"
      ],
      "metadata": {
        "id": "ih7cZa2lhryV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(2)"
      ],
      "metadata": {
        "id": "_EP42mHIcDAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and testing set"
      ],
      "metadata": {
        "id": "1y50b4jgbIz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "fsQy0rMJirw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "s_hu29-spmU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using DecisionTree as base model\n",
        "giniDecisionTree = DecisionTreeClassifier(criterion='gini', random_state = 100,\n",
        "                                          max_depth=3, class_weight = 'balanced', min_samples_leaf = 5)\n",
        "giniDecisionTree.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "GHEAgLPWi5W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediciton using DecisionTree\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "cLx7Ts_ni8M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CatBoost"
      ],
      "metadata": {
        "id": "rt5YFRSCdno1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CatBoostClassifier object\n",
        "CatBoost_clf = CatBoostClassifier(iterations=5,\n",
        "                                  learning_rate=0.1,\n",
        "                                  #loss_function='CrossEntropy'\n",
        "                                  )"
      ],
      "metadata": {
        "id": "k_97DlGji_RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cat_features = list(range(0, X.shape[1]))\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "EInDVBsmjB2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction using CatBoost\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "9sgR8EnjjGwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Classification report for CatBoost model\n",
        "print('Classification Report for CatBoost:')\n",
        "print(classification_report(y_test, cbr_prediction))"
      ],
      "metadata": {
        "id": "8a5SLBJzlb_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "ObSCMRsW3paH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create XGBClassifier object\n",
        "XGB_clf = XGBClassifier(learning_rate = 0.1)"
      ],
      "metadata": {
        "id": "Zs4IP_G8le9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit on training set\n",
        "XGB_clf.fit(x_train, y_train,\n",
        "            eval_set = [(x_train, y_train), (x_test, y_test)],\n",
        "            verbose = False)"
      ],
      "metadata": {
        "id": "c2ddPSXf5CBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction using XGBClassifier\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "uuRnPnok5SlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report for XGBoost\n",
        "\n",
        "print('Classification Report for XGBoost:')\n",
        "print(classification_report(y_test, XGB_prediction))"
      ],
      "metadata": {
        "id": "DTPyVR8k6Seh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM"
      ],
      "metadata": {
        "id": "x5Qr8gng6jLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LGBMClassifier object\n",
        "LGBM_clf = LGBMClassifier(learning_rate = 0.1)"
      ],
      "metadata": {
        "id": "dpMKEL4g6by0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit on training set\n",
        "LGBM_clf.fit(x_train, y_train,\n",
        "             eval_set = [(x_train, y_train), (x_test, y_test)])"
      ],
      "metadata": {
        "id": "iGC7j1tu68Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction using LGBMClassifier\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "_N1BW1X47E9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report for LGBM\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "hHllXW8O7Zrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference Reading:\n",
        "\n",
        "https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm"
      ],
      "metadata": {
        "id": "WEzk4g86PDEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7aSMPH1IFvRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select the FALSE statement: { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"CatBoost can internally handle categorical variables in the data\", \"XGBoost cannot handle categorical features by itself, it only accepts numerical values similar to Random Forest\", \"LightGBM uses a histogram-based method for selecting the best split in order to speed up the training process\", \"All the above\", \"None of the above\"]"
      ],
      "metadata": {
        "id": "XVCixTceFvnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "metadata": {
        "id": "Zk4ucOnhF0Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "uBbV6SC4F3Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "metadata": {
        "id": "QmwHNdoGF7gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "metadata": {
        "id": "Irlr_Yw_F9o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "metadata": {
        "id": "Lb82omwOGAqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Tp3rbU1XGDZ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}